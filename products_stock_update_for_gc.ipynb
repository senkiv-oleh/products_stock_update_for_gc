{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/senkiv-oleh/products_stock_update_for_gc/blob/master/products_stock_update_for_gc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfgLZkXuXHTY",
        "outputId": "ead92246-3ceb-4c87-91a1-f874b75d4a0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.33.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: urllib3~=2.4.0 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.4.0->selenium) (2.4.0)\n",
            "Collecting trio~=0.30.0 (from selenium)\n",
            "  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.12.2 (from selenium)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: certifi>=2025.4.26 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.4.26)\n",
            "Collecting typing_extensions~=4.13.2 (from selenium)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.30.0->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.4.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
            "Downloading selenium-4.33.0-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.30.0-py3-none-any.whl (499 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: wsproto, typing_extensions, outcome, trio, trio-websocket, selenium\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.14.0\n",
            "    Uninstalling typing_extensions-4.14.0:\n",
            "      Successfully uninstalled typing_extensions-4.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed outcome-1.3.0.post0 selenium-4.33.0 trio-0.30.0 trio-websocket-0.12.2 typing_extensions-4.13.2 wsproto-1.2.0\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,557 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,776 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,296 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,037 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,250 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,750 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,986 kB]\n",
            "Fetched 23.0 MB in 3s (8,572 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  apparmor chromium-browser libfuse3-3 libudev1 snapd squashfs-tools\n",
            "  systemd-hwe-hwdb udev\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils fuse3 zenity | kdialog\n",
            "The following NEW packages will be installed:\n",
            "  apparmor chromium-browser chromium-chromedriver libfuse3-3 snapd\n",
            "  squashfs-tools systemd-hwe-hwdb udev\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 8 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 30.3 MB of archives.\n",
            "After this operation, 123 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.4 [598 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.16 [76.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.16 [1,557 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.67.1+22.04 [27.8 MB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [49.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [2,308 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n",
            "Fetched 30.3 MB in 1s (45.6 MB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package apparmor.\n",
            "(Reading database ... 126111 files and directories currently installed.)\n",
            "Preparing to unpack .../apparmor_3.0.4-2ubuntu2.4_amd64.deb ...\n",
            "Unpacking apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Selecting previously unselected package squashfs-tools.\n",
            "Preparing to unpack .../squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n",
            "Unpacking squashfs-tools (1:4.5-3build1) ...\n",
            "Preparing to unpack .../libudev1_249.11-0ubuntu3.16_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.16) over (249.11-0ubuntu3.12) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.16) ...\n",
            "Selecting previously unselected package udev.\n",
            "(Reading database ... 126311 files and directories currently installed.)\n",
            "Preparing to unpack .../udev_249.11-0ubuntu3.16_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.16) ...\n",
            "Selecting previously unselected package libfuse3-3:amd64.\n",
            "Preparing to unpack .../libfuse3-3_3.10.5-1build1_amd64.deb ...\n",
            "Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Selecting previously unselected package snapd.\n",
            "Preparing to unpack .../snapd_2.67.1+22.04_amd64.deb ...\n",
            "Unpacking snapd (2.67.1+22.04) ...\n",
            "Setting up apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n",
            "Setting up squashfs-tools (1:4.5-3build1) ...\n",
            "Setting up udev (249.11-0ubuntu3.16) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Setting up snapd (2.67.1+22.04) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service → /lib/systemd/system/snapd.apparmor.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service → /lib/systemd/system/snapd.autoimport.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service → /lib/systemd/system/snapd.core-fixup.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service → /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service → /lib/systemd/system/snapd.service.\n",
            "Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer → /lib/systemd/system/snapd.snap-repair.timer.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket → /lib/systemd/system/snapd.socket.\n",
            "Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service → /lib/systemd/system/snapd.system-shutdown.service.\n",
            "Selecting previously unselected package chromium-browser.\n",
            "(Reading database ... 126540 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "=> Installing the chromium snap\n",
            "==> Checking connectivity with the snap store\n",
            "===> System doesn't have a working snapd, skipping\n",
            "Unpacking chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../systemd-hwe-hwdb_249.11.5_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Processing triggers for udev (249.11-0ubuntu3.16) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "Drive service built successfully.\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install -y chromium-chromedriver\n",
        "\n",
        "from google.auth import credentials\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2.service_account import Credentials\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaIoBaseDownload, MediaIoBaseDownload , MediaIoBaseUpload\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "from io import BytesIO\n",
        "from openpyxl import Workbook\n",
        "import google.auth\n",
        "import gspread\n",
        "from ftplib import FTP\n",
        "import io\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "import sys\n",
        "import datetime\n",
        "import pytz\n",
        "import time\n",
        "import xlrd\n",
        "import xml.etree.ElementTree as ET\n",
        "import zipfile\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support import expected_conditions as EC  # Import expected_conditions\n",
        "from selenium.webdriver.support.ui import WebDriverWait  # Import WebDriverWait\n",
        "\n",
        "#Download a file from an Google Spreadsheet\n",
        "def download_google_sheet(spreadsheet_id, gid):\n",
        "    download_url = f\"https://docs.google.com/spreadsheets/d/{spreadsheet_id}/export?format=xlsx&gid={gid}\"\n",
        "    response = requests.get(download_url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        print(\"Google Sheet downloaded successfully.\")\n",
        "        return io.BytesIO(response.content)\n",
        "    else:\n",
        "        print(f\"Failed to download file. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "#Download a file from an external URL\n",
        "def download_file_from_url(url):\n",
        "  headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\"\n",
        "        }\n",
        "\n",
        "  try:\n",
        "    response = requests.get(url, headers=headers)\n",
        "    response.raise_for_status()\n",
        "    print(\"File downloaded successfully.\")\n",
        "    return BytesIO(response.content)\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading file: {e}\")\n",
        "    return None\n",
        "\n",
        "# Upload XML file to Google Drive\n",
        "def upload_to_drive_xml(file_io, file_name, folder_id):\n",
        "    delete_old_files(file_name, folder_id)\n",
        "    file_metadata = {\n",
        "        'name': file_name,\n",
        "        'parents': [folder_id],\n",
        "        'mimeType': 'application/xml'  # MIME type for XML\n",
        "    }\n",
        "    media = MediaIoBaseUpload(file_io, mimetype='application/xml')\n",
        "\n",
        "    try:\n",
        "        file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "        print(f\"File uploaded to Google Drive with ID: {file.get('id')}\")\n",
        "        return file.get('id')\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while uploading the file: {e}\")\n",
        "\n",
        "# Delete old file from drive\n",
        "def delete_old_files(file_name, folder_id):\n",
        "    try:\n",
        "        query = f\"name='{file_name}' and '{folder_id}' in parents and trashed=false\"\n",
        "        results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
        "        files = results.get('files', [])\n",
        "\n",
        "        if files:\n",
        "            for file in files:\n",
        "                drive_service.files().delete(fileId=file['id']).execute()\n",
        "                print(f\"Deleted old file: {file['name']} (ID: {file['id']})\")\n",
        "        else:\n",
        "            print(\"No old files to delete.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while deleting old files: {e}\")\n",
        "\n",
        "#Upload files to Drive\n",
        "def upload_to_drive(file_io, file_name, folder_id):\n",
        "    delete_old_files(file_name, folder_id)\n",
        "    file_metadata = {\n",
        "        'name': file_name,\n",
        "        'parents': [folder_id],\n",
        "        'mimeType': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'\n",
        "    }\n",
        "    media = MediaIoBaseUpload(file_io, mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')\n",
        "\n",
        "    try:\n",
        "        file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "        print(f\"File uploaded to Google Drive with ID: {file.get('id')}\")\n",
        "        return file.get('id')\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while uploading the file: {e}\")\n",
        "\n",
        "def upload_to_drive_from_content(file_path, file_name, folder_id):\n",
        "    # Ensure the file exists\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"The file {file_name} {folder_id} {file_path} was not found in /content.\")\n",
        "        return\n",
        "\n",
        "    # Open the file as a binary stream\n",
        "    with open(file_path, \"rb\") as file_io:\n",
        "        file_metadata = {\n",
        "            'name': file_name,\n",
        "            'parents': [folder_id],\n",
        "            'mimeType': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'\n",
        "        }\n",
        "        media = MediaIoBaseUpload(file_io, mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')\n",
        "\n",
        "        try:\n",
        "            file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "            print(f\"File uploaded to Google Drive with ID: {file.get('id')}\")\n",
        "            return file.get('id')\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while uploading the file: {e}\")\n",
        "\n",
        "#Read file from Drive by id - returns file stream\n",
        "def read_file_from_drive(file_id):\n",
        "    request = drive_service.files().get_media(fileId=file_id)\n",
        "    file_io = io.BytesIO()\n",
        "    downloader = MediaIoBaseDownload(file_io, request)\n",
        "\n",
        "    try:\n",
        "        done = False\n",
        "        while not done:\n",
        "            status, done = downloader.next_chunk()\n",
        "            print(f\"Download {int(status.progress() * 100)}% complete.\")\n",
        "        file_io.seek(0)\n",
        "        return file_io\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while downloading the file from Google Drive: {e}\")\n",
        "        return None\n",
        "\n",
        "#Read file from Drive by name - returns file stream\n",
        "def read_file_from_drive_by_name(file_name, folder_id):\n",
        "    query = f\"name='{file_name}' and '{folder_id}' in parents and trashed=false\"\n",
        "    results = drive_service.files().list(q=query, fields=\"files(id)\").execute()\n",
        "    files = results.get('files', [])\n",
        "\n",
        "    if not files:\n",
        "        print(f\"No file found with the name '{file_name}' in the specified folder.\")\n",
        "        return None\n",
        "\n",
        "    file_id = files[0]['id']\n",
        "    request = drive_service.files().get_media(fileId=file_id)\n",
        "    file_io = io.BytesIO()\n",
        "    downloader = MediaIoBaseDownload(file_io, request)\n",
        "\n",
        "    try:\n",
        "        done = False\n",
        "        while not done:\n",
        "            status, done = downloader.next_chunk()\n",
        "            print(f\"Download {int(status.progress() * 100)}% complete.\")\n",
        "        file_io.seek(0)\n",
        "        return file_io\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while downloading the file from Google Drive: {e}\")\n",
        "        return None\n",
        "\n",
        "#BIO related functions\n",
        "def process_excel_BIO(file_io):\n",
        "    try:\n",
        "        columns_to_read = ['Штрих-код', 'Назва', 'Ціна РРЦ', 'Залишки']\n",
        "        bio = pd.read_excel(file_io, usecols=columns_to_read, engine='openpyxl')\n",
        "\n",
        "        bio = bio[bio['Штрих-код'].str.strip() != '']\n",
        "        bio['Штрих-код'] = 'BIO' + bio['Штрих-код'].astype(str)\n",
        "        bio['stock_status'] = bio['Залишки'].apply(lambda x: 'outofstock' if x == 0 else 'instock')\n",
        "        bio = bio[~bio['Штрих-код'].str.contains('nan', case=False)]\n",
        "        bio.rename(columns={\n",
        "            'Штрих-код': 'vendor_code',\n",
        "            'Назва': 'name',\n",
        "            'Залишки': 'availability',\n",
        "            'Ціна РРЦ': 'price'\n",
        "        }, inplace=True)\n",
        "\n",
        "        print(\"Processed DataFrame:\")\n",
        "        print(bio.head())\n",
        "        return bio\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing the Excel file: {e}\")\n",
        "        return None\n",
        "\n",
        "def read_file_from_drive_partial_name(partial_name, folder_id):\n",
        "    query = f\"name contains '{partial_name}' and '{folder_id}' in parents and trashed=false\"\n",
        "    results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
        "    files = results.get('files', [])\n",
        "\n",
        "    if not files:\n",
        "        print(f\"No file found with '{partial_name}' in its name in the specified folder.\")\n",
        "        return None\n",
        "\n",
        "    # Get the ID and name of the first matching file\n",
        "    file_id = files[0]['id']\n",
        "    file_name = files[0]['name']\n",
        "    print(f\"Found file: Name: {file_name}, ID: {file_id}\")\n",
        "\n",
        "    # Download the file\n",
        "    request = drive_service.files().get_media(fileId=file_id)\n",
        "    file_io = io.BytesIO()\n",
        "    downloader = MediaIoBaseDownload(file_io, request)\n",
        "\n",
        "    try:\n",
        "        done = False\n",
        "        while not done:\n",
        "            status, done = downloader.next_chunk()\n",
        "            print(f\"Download {int(status.progress() * 100)}% complete.\")\n",
        "        file_io.seek(0)\n",
        "        return file_io  # Return the file as a file-like object\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while downloading the file from Google Drive: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_BIO(spreadsheet_id, gid, folder_id, file_name):\n",
        "    file_io = download_google_sheet(spreadsheet_id, gid)\n",
        "\n",
        "    if file_io:\n",
        "        file_io.seek(0)\n",
        "        file_id = upload_to_drive(file_io, file_name, folder_id)\n",
        "\n",
        "        if file_id:\n",
        "            uploaded_file_io = read_file_from_drive(file_id)\n",
        "            if uploaded_file_io:\n",
        "                processed_data = process_excel_BIO(uploaded_file_io)\n",
        "                return processed_data\n",
        "    else:\n",
        "        print(\"Download failed. The file will not be processed.\")\n",
        "\n",
        "#Oven\n",
        "def process_excel_Oven(file_io):\n",
        "    try:\n",
        "        oven = pd.read_excel(file_io, engine='openpyxl')\n",
        "\n",
        "        oven.columns = ['Назва', 'Штрихкод', 'Артикул', 'Наявність', 'del']\n",
        "        oven = oven.drop(oven.columns[-1], axis=1)\n",
        "        oven = oven.dropna(subset=['Наявність'])\n",
        "        oven = oven.drop(columns=['Штрихкод'])\n",
        "\n",
        "        oven = oven[oven['Артикул'].notna()]\n",
        "        oven['Артикул'] = 'Oven' + oven['Артикул'].astype(str)\n",
        "        oven['stock_status'] = oven['Наявність'].apply(lambda x: 'outofstock' if x == 'ні' else 'instock')\n",
        "        oven['price'] = 0\n",
        "\n",
        "        oven.rename(columns={\n",
        "            'Артикул': 'vendor_code',\n",
        "            'Назва': 'name',\n",
        "            'Наявність': 'availability'\n",
        "        }, inplace=True)\n",
        "\n",
        "        print(\"Data from the Excel file:\")\n",
        "        print(oven.head())  # Display the first few rows of the DataFrame\n",
        "        return oven\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the Excel file: {e}\")\n",
        "\n",
        "def process_Oven(spreadsheet_id, gid, folder_id, file_name):\n",
        "    file_io = download_google_sheet(spreadsheet_id, gid)\n",
        "\n",
        "    if file_io:\n",
        "        file_io.seek(0)\n",
        "        file_id = upload_to_drive(file_io, file_name, folder_id)\n",
        "\n",
        "        if file_id:\n",
        "            uploaded_file_io = read_file_from_drive(file_id)\n",
        "            if uploaded_file_io:\n",
        "                processed_data = process_excel_Oven(uploaded_file_io)\n",
        "                return processed_data\n",
        "    else:\n",
        "        print(\"Download failed. The file will not be processed.\")\n",
        "\n",
        "#VS\n",
        "def process_excel_VS(file_io):\n",
        "    try:\n",
        "        # Convert .xls to .xlsx if necessary\n",
        "        file_converted = convert_xls_to_xlsx(file_io)\n",
        "\n",
        "        if not file_converted:\n",
        "            print(\"File conversion failed.\")\n",
        "            return\n",
        "        # Read the .xlsx file using the appropriate engine\n",
        "        vs = pd.read_excel(file_converted,\n",
        "                           engine='openpyxl')\n",
        "\n",
        "        # Drop unnecessary rows\n",
        "        vs = vs.drop(index=vs.index[:4]).reset_index(drop=True)\n",
        "        vs.rename(columns={\n",
        "                'Unnamed: 1': 'vendor_code',\n",
        "                'Unnamed: 2': 'name',\n",
        "                'Unnamed: 6': 'price',\n",
        "                'Unnamed: 3': 'availability'\n",
        "            }, inplace=True)\n",
        "\n",
        "        vs = vs.loc[:, ~vs.columns.str.startswith('Unnamed')]\n",
        "\n",
        "        vs['vendor_code'] = 'VS' + vs['vendor_code'].astype(str)\n",
        "        vs['price'] =  vs['price'] * 1.42\n",
        "        vs['price'] =  vs['price'].fillna(0)\n",
        "        vs['stock_status'] = vs['availability'].apply(map_stock_level_vs)\n",
        "        vs = vs[vs['name'].notna()]\n",
        "        vs = vs.infer_objects()\n",
        "\n",
        "        # Display the processed data\n",
        "        print(\"Data from the Excel file:\")\n",
        "        print(vs.head())  # Display the first few rows of the DataFrame\n",
        "        return vs\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the Excel file: {e}\")\n",
        "\n",
        "def map_stock_level_vs(symbol):\n",
        "    if symbol == '+++':\n",
        "        return 'instock'\n",
        "    elif symbol == '++':\n",
        "        return 'instock'\n",
        "    elif symbol == '+':\n",
        "        return 'instock'\n",
        "    elif symbol == '-':\n",
        "        return 'outofstock'\n",
        "    else:\n",
        "        return 'Unknown'\n",
        "\n",
        "def process_VS(url, folder_id, file_name):\n",
        "    file_io = download_file_from_url(url)\n",
        "\n",
        "    if file_io:\n",
        "        file_io.seek(0)\n",
        "        file_id = upload_to_drive(file_io, file_name, folder_id)\n",
        "\n",
        "        if file_id:\n",
        "            uploaded_file_io = read_file_from_drive(file_id)\n",
        "\n",
        "            if uploaded_file_io:\n",
        "                processed_data = process_excel_VS(uploaded_file_io)\n",
        "                return processed_data\n",
        "    else:\n",
        "        print(\"Download failed. The file will not be processed.\")\n",
        "\n",
        "#VM\n",
        "def delete_files_with_partial_name(partial_name, folder_id):\n",
        "    # Query to find files with names containing the partial name in the specified folder\n",
        "    query = f\"name contains '{partial_name}' and '{folder_id}' in parents and trashed=false\"\n",
        "    results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
        "    files = results.get('files', [])\n",
        "\n",
        "    if not files:\n",
        "        print(f\"No files found with '{partial_name}' in their names in the specified folder.\")\n",
        "        return\n",
        "\n",
        "    # Loop through each matching file and delete it\n",
        "    for file in files:\n",
        "        file_id = file['id']\n",
        "        file_name = file['name']\n",
        "        try:\n",
        "            drive_service.files().delete(fileId=file_id).execute()\n",
        "            print(f\"Deleted file: {file_name} (ID: {file_id})\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while deleting file '{file_name}': {e}\")\n",
        "\n",
        "\n",
        "def download_vm():\n",
        "    try:\n",
        "        # Setup download directory\n",
        "        download_dir = '/content'\n",
        "        ptint()\n",
        "\n",
        "        # Chrome options for headless browser\n",
        "        chrome_options = Options()\n",
        "        chrome_options.add_argument('--headless')\n",
        "        chrome_options.add_argument('--no-sandbox')\n",
        "        chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "        chrome_options.add_argument('--disable-infobars')\n",
        "        chrome_options.add_experimental_option('prefs', {\n",
        "            \"download.default_directory\": download_dir,\n",
        "            \"download.prompt_for_download\": False,\n",
        "            \"download.directory_upgrade\": True,\n",
        "            \"safebrowsing.enabled\": True\n",
        "        })\n",
        "\n",
        "        # Selenium WebDriver setup\n",
        "        driver = webdriver.Chrome(options=chrome_options)\n",
        "        driver.get('https://vetmarketgroup.com/')\n",
        "        username = driver.find_element(By.NAME, 'email').send_keys('meow@amigovet.net')\n",
        "        password = driver.find_element(By.NAME, 'password').send_keys('fjkJTt7B')\n",
        "\n",
        "        try:\n",
        "            cookie_button = WebDriverWait(driver, 10).until(\n",
        "                EC.element_to_be_clickable((By.XPATH, \"//span[contains(text(), 'OK')]\"))\n",
        "            )\n",
        "            cookie_button.click()\n",
        "\n",
        "            login_button = WebDriverWait(driver, 1).until(\n",
        "                EC.element_to_be_clickable((By.XPATH, \"//input[@class='registr' and @value=' Вхід в особистий кабінет']\"))\n",
        "            )\n",
        "            login_button.click()\n",
        "            print(\"Clicked the login button successfully.\")\n",
        "        except Exception as e:\n",
        "            print(\"An error occurred while clicking the login button:\", e)\n",
        "\n",
        "        time.sleep(2)\n",
        "        driver.get('https://vetmarketgroup.com/getprice')\n",
        "        time.sleep(2)\n",
        "        driver.quit()\n",
        "\n",
        "        print(\"Download completed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while downloading file: {e}\")\n",
        "\n",
        "def process_excel_VM(file_io):\n",
        "    try:\n",
        "        columns_to_read = ['Арт', 'Цінова група/ Номенклатура/ Характеристика номенклатури', 'Цена']\n",
        "        dtype = {\n",
        "                'Арт': str,\n",
        "                'Цінова група/ Номенклатура/ Характеристика номенклатури': str,\n",
        "                'Цена': float\n",
        "            }\n",
        "        vm = pd.read_excel(file_io,\n",
        "                           header=9,\n",
        "                           dtype = dtype,\n",
        "                           usecols=columns_to_read,\n",
        "                           engine='openpyxl')  # Specify openpyxl as the engine\n",
        "\n",
        "        vm = vm.drop(index=vm.index[:4]).reset_index(drop=True)\n",
        "        vm['Арт'] = 'VM' + vm['Арт'].str.zfill(6)\n",
        "\n",
        "        vm = vm[vm['Цена'].notna()]\n",
        "        vm = vm.infer_objects()\n",
        "\n",
        "        vm['stock_status'] = 'instock'\n",
        "        vm['availability'] = 'available'\n",
        "\n",
        "        vm.rename(columns={\n",
        "            'Арт': 'vendor_code',\n",
        "            'Цінова група/ Номенклатура/ Характеристика номенклатури': 'name',\n",
        "            'Цена': 'price'\n",
        "        }, inplace=True)\n",
        "\n",
        "        vm['price'] = vm['price'].apply(apply_markup)\n",
        "\n",
        "        # Display the processed data\n",
        "        print(\"Data from the Excel file:\")\n",
        "        print(vm.head())  # Display the first few rows of the DataFrame\n",
        "        return vm\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the Excel file: {e}\")\n",
        "\n",
        "def apply_markup(price):\n",
        "  if price < 300:\n",
        "    return price * 1.45\n",
        "  elif price < 1000:\n",
        "    return price * 1.4\n",
        "  else:\n",
        "    return price * 1.37\n",
        "\n",
        "def wait_for_file(file_name, folder_id, max_wait=60, interval=7):\n",
        "    elapsed = 0\n",
        "    while elapsed < max_wait:\n",
        "        file_io = read_file_from_drive_partial_name(file_name, folder_id)\n",
        "        if file_io:\n",
        "            file_io.seek(0)\n",
        "            initial_size = file_io.getbuffer().nbytes\n",
        "            time.sleep(interval)  # Wait a bit to re-check\n",
        "            file_io.seek(0)\n",
        "            if file_io.getbuffer().nbytes == initial_size:\n",
        "                return file_io\n",
        "        elapsed += interval\n",
        "        time.sleep(interval)\n",
        "    return None  # Return None if file not found within max_wait\n",
        "\n",
        "def process_VM(folder_id, file_name):\n",
        "    file_io = read_file_from_drive_by_name(file_name, folder_id)\n",
        "    print(f\"Download failed. The file will not be processed. {file_io} {folder_id} {file_name}\")\n",
        "\n",
        "    if file_io:\n",
        "        file_io.seek(0)\n",
        "        processed_data = process_excel_VM(file_io)\n",
        "        print(f\"Processed data = {processed_data}\")\n",
        "\n",
        "        return processed_data\n",
        "    else:\n",
        "        print(\"Download failed. The file will not be processed.\")\n",
        "\n",
        "#NTP\n",
        "def process_excel_NTP(file_io):\n",
        "    try:\n",
        "        # Define the columns to read and data types\n",
        "        columns_to_read = ['Артикул', 'Название модификации (UA)', 'Название (UA)', 'РРЦ','Наличие']\n",
        "        ntp = pd.read_excel(file_io, usecols=columns_to_read, engine='openpyxl')\n",
        "\n",
        "        ntp['Артикул'] = 'NTP' + ntp['Артикул']\n",
        "        ntp['stock_status'] = ntp['Наличие'].apply(\n",
        "            lambda x: 'outofstock' if x == 'Немає в наявності'\n",
        "            else 'instock' if x == 'В наявності'\n",
        "            else '' if x == ''\n",
        "            else 'unknown'\n",
        "        )\n",
        "\n",
        "        ntp = ntp[ntp['Наличие'].notna()]\n",
        "\n",
        "        ntp['Название модификации (UA)'] = ntp['Название модификации (UA)'].fillna(ntp['Название (UA)'])\n",
        "        ntp['Название модификации (UA)'] = ntp['Название модификации (UA)'].fillna('')\n",
        "\n",
        "        ntp = ntp.drop(columns=['Название (UA)'])\n",
        "\n",
        "        ntp.rename(columns={\n",
        "            'Артикул': 'vendor_code',\n",
        "            'Название модификации (UA)': 'name',\n",
        "            'Наличие': 'availability',\n",
        "            'РРЦ': 'price'\n",
        "        }, inplace=True)\n",
        "\n",
        "        print(\"Data from the Excel file:\")\n",
        "        print(ntp.head())  # Display the first few rows of the DataFrame\n",
        "        return ntp\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the Excel file: {e}\")\n",
        "\n",
        "def process_NTP(url, folder_id, file_name):\n",
        "    file_io = download_file_from_url(url)\n",
        "\n",
        "    if file_io:\n",
        "        file_io.seek(0)\n",
        "        file_id = upload_to_drive(file_io, file_name, folder_id)\n",
        "\n",
        "        if file_id:\n",
        "            uploaded_file_io = read_file_from_drive(file_id)\n",
        "\n",
        "            if uploaded_file_io:\n",
        "                processed_data = process_excel_NTP(uploaded_file_io)\n",
        "                return processed_data\n",
        "    else:\n",
        "        print(\"Download failed. The file will not be processed.\")\n",
        "\n",
        "\n",
        "#HILL\n",
        "def process_excel_HILL(file_io):\n",
        "    try:\n",
        "        columns_to_read = ['Артикул', 'Наименование', 'Статус остатков', 'Ціна за од. Рекомендованная цена']\n",
        "\n",
        "        dtype = {\n",
        "            'Артикул': str,  # Ensure Артикул is read as a string\n",
        "            'Наименование': str,  # Ensure Наименование is read as a string\n",
        "            'Статус остатков': str,  # Ensure Статус остатков is read as a string\n",
        "        }\n",
        "\n",
        "        # Read the downloaded .xlsx file into a DataFrame\n",
        "        hill = pd.read_excel(file_io, header=4, dtype=dtype, usecols=columns_to_read)\n",
        "\n",
        "        # Drop the first three rows of the DataFrame and reset index\n",
        "        hill = hill.drop(index=hill.index[:3]).reset_index(drop=True)\n",
        "\n",
        "        # Format the 'Артикул' column\n",
        "        hill['Артикул'] = 'HILL' + hill['Артикул'].str.zfill(5)\n",
        "\n",
        "        # Filter out rows where 'Артикул' is not available\n",
        "        hill = hill[hill['Артикул'].notna()]\n",
        "\n",
        "        # Determine stock status based on 'Статус остатков'\n",
        "        hill['stock_status'] = hill['Статус остатков'].apply(lambda x: 'outofstock' if x == 'Нет на складе' else 'instock')\n",
        "\n",
        "        # Rename columns for consistency\n",
        "        hill.rename(columns={\n",
        "            'Артикул': 'vendor_code',\n",
        "            'Наименование': 'name',\n",
        "            'Статус остатков': 'availability',\n",
        "            'Ціна за од. Рекомендованная цена': 'price'\n",
        "        }, inplace=True)\n",
        "\n",
        "        print(\"Data from the Excel file:\")\n",
        "        print(hill.head())  # Display the first few rows of the DataFrame\n",
        "        return hill\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the Excel file: {e}\")\n",
        "\n",
        "# Update the process_HILL function to pass the folder ID\n",
        "def process_HILL_xls(folder_id, file_name):\n",
        "    file_io = read_file_from_drive_by_name(file_name, folder_id)\n",
        "    if file_io:\n",
        "        file_iop = convert_xls_to_xlsx(file_io)\n",
        "\n",
        "        if file_iop:\n",
        "            file_iop.seek(0)\n",
        "            processed_data = process_excel_HILL(file_iop)\n",
        "            return processed_data\n",
        "        else:\n",
        "            print(\"Download failed. The file will not be processed.\")\n",
        "\n",
        "def process_HILL(folder_id, file_name):\n",
        "    file_io = read_file_from_drive_by_name(file_name, folder_id)\n",
        "    if file_io:\n",
        "        file_io.seek(0)\n",
        "        processed_data = process_excel_HILL(file_io)\n",
        "        return processed_data\n",
        "    else:\n",
        "        print(\"Download failed. The file will not be processed.\")\n",
        "\n",
        "#Alfa\n",
        "def process_excel_Alfa(file_io):\n",
        "    try:\n",
        "        columns_to_read = ['Штрихкод', 'Назва продукту', 'Залишок', 'РРЦ, грн']\n",
        "        dtype = {\n",
        "            'Штрихкод': str,\n",
        "            'Назва продукту': str,\n",
        "            'Залишок': 'float64'\n",
        "        }\n",
        "        alfa = pd.read_excel(file_io, header=1, dtype=dtype, usecols=columns_to_read)\n",
        "\n",
        "        alfa = alfa[alfa['Штрихкод'].notna()]\n",
        "\n",
        "        alfa['Штрихкод'] = 'Alfa' + alfa['Штрихкод'].str.zfill(5)\n",
        "\n",
        "        alfa['stock_status'] = alfa['Залишок'].apply(lambda x: 'outofstock' if x < 7 else 'instock')\n",
        "\n",
        "        alfa.rename(columns={\n",
        "            'Штрихкод': 'vendor_code',\n",
        "            'Назва продукту': 'name',\n",
        "            'Залишок': 'availability',\n",
        "            'РРЦ, грн': 'price'\n",
        "        }, inplace=True)\n",
        "\n",
        "        print(\"Data from the Excel file:\")\n",
        "        print(alfa.dtypes)\n",
        "        print(alfa.head())\n",
        "\n",
        "        return alfa\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the Excel file: {e}\")\n",
        "\n",
        "def process_Alfa(folder_id, file_name):\n",
        "    # Check the file extension based on the file_name parameter\n",
        "    if file_name.lower().endswith('.xls'):\n",
        "        # File is .xls, needs conversion\n",
        "        file_io = read_file_from_drive_by_name(file_name, folder_id)\n",
        "        if file_io:\n",
        "            file_iop = convert_xls_to_xlsx(file_io)\n",
        "            if file_iop:\n",
        "                file_iop.seek(0)\n",
        "                processed_data = process_excel_Alfa(file_iop)\n",
        "                return processed_data\n",
        "            else:\n",
        "                print(\"File conversion failed. The file will not be processed.\")\n",
        "                return None\n",
        "        else:\n",
        "            print(\"File not found in the specified folder.\")\n",
        "            return None\n",
        "    elif file_name.lower().endswith('.xlsx'):\n",
        "        # File is .xlsx, no conversion needed\n",
        "        file_io = read_file_from_drive_by_name(file_name, folder_id)\n",
        "        if file_io:\n",
        "            file_io.seek(0)\n",
        "            processed_data = process_excel_Alfa(file_io)\n",
        "            return processed_data\n",
        "        else:\n",
        "            print(\"File not found in the specified folder.\")\n",
        "            return None\n",
        "    else:\n",
        "        # Unsupported file format\n",
        "        print(\"Unsupported file format. Only .xls and .xlsx files are supported.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "#MG\n",
        "def process_excel_MG(file_io):\n",
        "    try:\n",
        "        # Define the columns to read\n",
        "        columns_to_read = ['Штрих код', 'Найменування ', 'Роздрібна ціна, з ПДВ ', 'Залишки актуальні', 'Період дії акції']\n",
        "\n",
        "        # Read the Excel file\n",
        "        mg = pd.read_excel(file_io, usecols=columns_to_read, engine='openpyxl')\n",
        "\n",
        "        # Convert \"Штрих код\" to string to avoid concatenation errors\n",
        "        mg['Штрих код'] = mg['Штрих код'].astype(str)\n",
        "\n",
        "        # Prefix the barcode with \"MG\"\n",
        "        mg['Штрих код'] = 'MG' + mg['Штрих код']\n",
        "\n",
        "        # Ensure \"Роздрібна ціна, з ПДВ \" contains only numeric values\n",
        "        mg['Роздрібна ціна, з ПДВ '] = pd.to_numeric(mg['Роздрібна ціна, з ПДВ '], errors='coerce')\n",
        "\n",
        "        # Ensure \"Залишки актуальні\" is numeric, coercing errors to NaN\n",
        "        mg['Залишки актуальні'] = pd.to_numeric(mg['Залишки актуальні'], errors='coerce')\n",
        "\n",
        "        # Replace NaN in \"Залишки актуальні\" with 0\n",
        "        mg['Залишки актуальні'] = mg['Залишки актуальні'].fillna(0).astype('Int64')\n",
        "\n",
        "        # Filter rows: \"Період дії акції\" must be NaN, \"Роздрібна ціна, з ПДВ \" must not be NaN, and \"Найменування \" must not be empty\n",
        "        mg = mg[mg['Період дії акції'].isna() & mg['Роздрібна ціна, з ПДВ '].notna() & mg['Найменування '].notna()]\n",
        "\n",
        "        # Drop the \"Період дії акції\" column\n",
        "        mg = mg.drop(columns=['Період дії акції'])\n",
        "\n",
        "        # Add stock status based on availability\n",
        "        mg['stock_status'] = mg['Залишки актуальні'].apply(lambda x: 'instock' if x > 7 else 'outofstock')\n",
        "\n",
        "        # Rename columns\n",
        "        mg.rename(columns={\n",
        "            'Штрих код': 'vendor_code',\n",
        "            'Найменування ': 'name',\n",
        "            'Залишки актуальні': 'availability',\n",
        "            'Роздрібна ціна, з ПДВ ': 'price'\n",
        "        }, inplace=True)\n",
        "\n",
        "        print(\"Data from the Excel file:\")\n",
        "        print(mg.head())  # Display the first few rows of the DataFrame\n",
        "        return mg\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the Excel file: {e}\")\n",
        "\n",
        "def process_MG(folder_id, file_name):\n",
        "    file_io = read_file_from_drive_by_name(file_name, folder_id)\n",
        "    if file_io:\n",
        "        file_io.seek(0)\n",
        "        processed_data = process_excel_MG(file_io)\n",
        "        return processed_data\n",
        "    else:\n",
        "        print(\"Download failed. The file will not be processed.\")\n",
        "\n",
        "#NSTL\n",
        "def process_excel_NSTL(file_io):\n",
        "  try:\n",
        "    raw_data = pd.read_excel(file_io, header=None)\n",
        "\n",
        "        # Manually specify the relevant columns based on their position in the file\n",
        "        # Assuming the second \"Цена\" is in column 8 (zero-indexed, so it's 9th in Excel)\n",
        "    relevant_columns = {\n",
        "            1: 'vendor_code',\n",
        "            2: 'name',\n",
        "            5: 'price',\n",
        "            6: 'regular_avail',\n",
        "            7: 'promo_avail',\n",
        "        }\n",
        "\n",
        "    ### Subset the data to keep only the relevant columns\n",
        "    nstl = raw_data.iloc[1:, list(relevant_columns.keys())]\n",
        "    nstl.columns = relevant_columns.values()  # Rename columns\n",
        "\n",
        "    nstl = nstl.dropna(subset=['vendor_code'])\n",
        "    nstl = nstl[nstl['vendor_code'] != \"Штрихкод\"]\n",
        "\n",
        "    nstl['vendor_code'] = 'NSTL' + nstl['vendor_code'].astype(str)\n",
        "    nstl = nstl[nstl['vendor_code'].notna()]\n",
        "\n",
        "    nstl['price'] = nstl['price'].fillna(0).infer_objects(copy=False)\n",
        "    nstl['regular_avail'] = nstl['regular_avail'].fillna(0).infer_objects(copy=False)\n",
        "    nstl['promo_avail'] = nstl['promo_avail'].fillna(0).infer_objects(copy=False)\n",
        "\n",
        "    nstl['availability'] = nstl['regular_avail'] + nstl['promo_avail']\n",
        "    nstl = nstl.drop(columns=['regular_avail', 'promo_avail'])\n",
        "    nstl['stock_status'] = nstl['availability'].apply(lambda x: 'outofstock' if x == 0 else 'instock')\n",
        "\n",
        "    print(\"Data from the Excel file:\")\n",
        "    print(nstl)  # Display the first few rows of the DataFrame\n",
        "    return nstl\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred while reading the Excel file: {e}\")\n",
        "\n",
        "def process_NSTL(folder_id, file_name):\n",
        "    # Check the file extension based on the file_name parameter\n",
        "    if file_name.lower().endswith('.xls'):\n",
        "        # File is .xls, needs conversion\n",
        "        file_io = read_file_from_drive_by_name(file_name, folder_id)\n",
        "        if file_io:\n",
        "            file_iop = convert_xls_to_xlsx(file_io)\n",
        "            if file_iop:\n",
        "                file_iop.seek(0)\n",
        "                processed_data = process_excel_NSTL(file_iop)\n",
        "                return processed_data\n",
        "            else:\n",
        "                print(\"File conversion failed. The file will not be processed.\")\n",
        "                return None\n",
        "        else:\n",
        "            print(\"File not found in the specified folder.\")\n",
        "            return None\n",
        "    elif file_name.lower().endswith('.xlsx'):\n",
        "        # File is .xlsx, no conversion needed\n",
        "        file_io = read_file_from_drive_by_name(file_name, folder_id)\n",
        "        if file_io:\n",
        "            file_io.seek(0)\n",
        "            processed_data = process_excel_NSTL(file_io)\n",
        "            return processed_data\n",
        "        else:\n",
        "            print(\"File not found in the specified folder.\")\n",
        "            return None\n",
        "    else:\n",
        "        # Unsupported file format\n",
        "        print(\"Unsupported file format. Only .xls and .xlsx files are supported.\")\n",
        "        return None\n",
        "\n",
        "#DET\n",
        "def process_excel_DET(file_io):\n",
        "  try:\n",
        "    columns_to_read = ['Штрихкод', 'Найменування', 'Залишок', 'Ціна рекомендована, грн']\n",
        "    dtype = {\n",
        "                'Штрихкод': str,  # Ensure ProductID is read as a string\n",
        "                'Найменування': str,     # Ensure Price is read as a float\n",
        "                'Залишок': str\n",
        "            }\n",
        "    det = pd.read_excel(file_io,\n",
        "                        header=5,\n",
        "                        dtype=dtype,\n",
        "                        usecols=columns_to_read)\n",
        "\n",
        "    # Verify 'det' is still a DataFrame after dropping rows\n",
        "    det = det.drop(index=det.index[:3]).reset_index(drop=True)\n",
        "\n",
        "    det['Штрихкод'] = 'DET' + det['Штрихкод']\n",
        "    det = det[det['Штрихкод'].notna()]\n",
        "    det['stock_status'] = det['Залишок'].apply(lambda x: 'outofstock' if x == 'Немає в наявності' else 'instock')\n",
        "    det['Ціна рекомендована, грн'] = det['Ціна рекомендована, грн'].fillna(0)\n",
        "\n",
        "    # Rename columns in the DataFrame\n",
        "    det = det.rename(columns={\n",
        "            'Штрихкод': 'vendor_code',\n",
        "            'Найменування': 'name',\n",
        "            'Залишок': 'availability',\n",
        "            'Ціна рекомендована, грн': 'price'\n",
        "        })\n",
        "\n",
        "    print(\"Data from the Excel file:\")\n",
        "    print(det.head())  # Display the first few rows of the DataFrame\n",
        "    return det\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred while reading the Excel file: {e}\")\n",
        "\n",
        "def process_DET(folder_id, file_name):\n",
        "    file_io = read_file_from_drive_by_name(file_name, folder_id)\n",
        "    if file_io:\n",
        "      file_io.seek(0)\n",
        "      processed_data = process_excel_DET(file_io)\n",
        "      return processed_data\n",
        "    else:\n",
        "      print(\"Download failed. The file will not be processed.\")\n",
        "\n",
        "#TRP\n",
        "def get_element_text(element, tag_name):\n",
        "    \"\"\"Safely gets the text content of an XML element by tag name.\"\"\"\n",
        "    tag = element.find(tag_name)\n",
        "    return tag.text.strip() if tag is not None and tag.text else ''\n",
        "\n",
        "def process_xml_TRP(file_io):\n",
        "    \"\"\"Extracts specific data from an XML file.\"\"\"\n",
        "    try:\n",
        "        # Parse the XML file\n",
        "        tree = ET.parse(file_io)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        # List to store extracted data\n",
        "        offers = []\n",
        "\n",
        "        # Iterate through each <offer> element\n",
        "        for offer in root.findall(\".//offer\"):\n",
        "            offer_id = offer.attrib.get('id', '')\n",
        "            prefixed_id = f\"TRP{offer_id}\" if offer_id else ''\n",
        "\n",
        "            stock_quantity = get_element_text(offer, 'stock_quantity')\n",
        "            price = get_element_text(offer, 'price')\n",
        "\n",
        "            offer_data = {\n",
        "                'Артикул': prefixed_id,  # Original key for renaming later\n",
        "                'Название модификации (UA)': get_element_text(offer, 'name_UA'),\n",
        "                'РРЦ': float(price) if price else 0.0,  # Convert price to float\n",
        "                'Наличие': int(stock_quantity)# Determine stock status\n",
        "            }\n",
        "            offers.append(offer_data)\n",
        "\n",
        "        # Create a DataFrame from the offers list\n",
        "        trp = pd.DataFrame(offers)\n",
        "\n",
        "        # Rename columns\n",
        "        trp.rename(columns={\n",
        "            'Артикул': 'vendor_code',\n",
        "            'Название модификации (UA)': 'name',\n",
        "            'Наличие': 'availability',\n",
        "            'РРЦ': 'price'\n",
        "        }, inplace=True)\n",
        "\n",
        "        trp['name'] = trp['name'].fillna(0)\n",
        "\n",
        "        trp['stock_status'] = trp['availability'].apply(lambda x: 'instock' if x > 0 else 'outofstock')\n",
        "\n",
        "        print(trp)\n",
        "        return trp  # Return the DataFrame\n",
        "\n",
        "    except ET.ParseError:\n",
        "        print(\"Error parsing the XML file.\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def process_TRP(url, file_name, folder_id):\n",
        "    file_io = download_file_from_url(url)\n",
        "\n",
        "    if file_io:\n",
        "        file_io.seek(0)\n",
        "        file_id = upload_to_drive_xml(file_io, file_name, folder_id)\n",
        "\n",
        "        if file_id:\n",
        "            uploaded_file_io = read_file_from_drive(file_id)\n",
        "\n",
        "            if uploaded_file_io:\n",
        "                processed_data = process_xml_TRP(uploaded_file_io)\n",
        "                return processed_data\n",
        "    else:\n",
        "        print(\"Download failed. The file will not be processed.\")\n",
        "\n",
        "def process_xml_feed(file_io):\n",
        "    \"\"\"Processes an XML file and extracts specific data into a DataFrame.\"\"\"\n",
        "    try:\n",
        "        # Parse the XML file\n",
        "        tree = ET.parse(file_io)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        # List to store extracted data\n",
        "        products = []\n",
        "\n",
        "        # Iterate through each <product> element\n",
        "        for product in root.findall(\".//product\"):\n",
        "            id = get_element_text(product, 'SKU')\n",
        "            title = get_element_text(product, 'title')\n",
        "            price = get_element_text(product, 'price')\n",
        "            sale_price = get_element_text(product, 'sale_price')\n",
        "            availability = get_element_text(product, 'availability')\n",
        "\n",
        "            cleaned_price = float(price.replace(' грн', '').strip()) if price else 0.0\n",
        "            cleaned_sale_price = float(sale_price.replace(' грн', '').strip()) if sale_price else 0.0\n",
        "\n",
        "            product_data = {\n",
        "                'id': id,\n",
        "                'name': title,\n",
        "                'price': cleaned_price,\n",
        "                'sale_price': cleaned_sale_price,\n",
        "                'availability': availability\n",
        "            }\n",
        "            products.append(product_data)\n",
        "\n",
        "        # Create a DataFrame from the products list\n",
        "        df = pd.DataFrame(products)\n",
        "        df['availability'] = df['availability'].apply(lambda x: 'outofstock' if x == 'out of stock' else 'instock')\n",
        "\n",
        "        print(df)\n",
        "        return df\n",
        "\n",
        "    except ET.ParseError as e:\n",
        "        print(f\"Error parsing XML file: {e}\")\n",
        "        return pd.DataFrame()\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "def fetch_yml_data(url):\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        root = ET.fromstring(response.content)\n",
        "\n",
        "        catalog_date = root.get(\"date\")\n",
        "        offers = []\n",
        "\n",
        "        for offer in root.findall(\".//offer\"):\n",
        "            offer_data = {\n",
        "                'id': offer.attrib['id'],\n",
        "                'name': get_element_text(offer, 'name'),\n",
        "                'price': get_element_text(offer, 'price'),\n",
        "                'quantity_in_stock': get_element_text(offer, 'quantity_in_stock'),\n",
        "                'vendorCode': get_element_text(offer, 'vendorCode'),\n",
        "            }\n",
        "            offers.append(offer_data)\n",
        "\n",
        "        return catalog_date, offers\n",
        "    else:\n",
        "        print(f\"Failed to retrieve the YML file. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "# Function to convert YML data to a DataFrame\n",
        "def yml_data_to_dataframe(url):\n",
        "    catalog_date, offers = fetch_yml_data(url)\n",
        "\n",
        "    if offers:\n",
        "        # Convert the offers list to a DataFrame\n",
        "        df = pd.DataFrame(offers)\n",
        "\n",
        "        # Convert 'price' and 'quantity_in_stock' to appropriate types\n",
        "        df['price'] = pd.to_numeric(df['price'].str.replace(',', '.'), errors='coerce')\n",
        "        df['quantity_in_stock'] = pd.to_numeric(df['quantity_in_stock'], errors='coerce')\n",
        "        df['stock_status_salesdrive'] = df['quantity_in_stock'].apply(lambda x: 'instock' if x > 0 else 'outofstock')\n",
        "\n",
        "        # Add the catalog date as a new column\n",
        "        df['catalog_date'] = catalog_date\n",
        "\n",
        "        return df\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def process_excel_SPC(file_io):\n",
        "  try:\n",
        "    columns_to_read = ['Код_товару', 'Назва_позиції_укр', 'Ціна', 'Наявність']\n",
        "    dtype = {\n",
        "                'Код_товару': str,  # Ensure ProductID is read as a string\n",
        "                'Назва_позиції_укр': str,     # Ensure Price is read as a float\n",
        "                'Ціна': 'float64',\n",
        "                'Наявність': str\n",
        "            }\n",
        "    spc = pd.read_excel(file_io,\n",
        "                        header=0,\n",
        "                        dtype = dtype,\n",
        "                        usecols=columns_to_read)\n",
        "\n",
        "    spc['Код_товару'] = 'SPC' + spc['Код_товару']\n",
        "    spc['stock_status'] = spc['Наявність'].apply(lambda x: 'outofstock' if x == '-' else 'instock')\n",
        "    spc['Наявність'] = \"'\" + spc['Наявність']\n",
        "\n",
        "    spc.rename(columns={\n",
        "            'Код_товару': 'vendor_code',\n",
        "            'Назва_позиції_укр': 'name',\n",
        "            'Наявність': 'availability',\n",
        "            'Ціна': 'price'\n",
        "        }, inplace=True)\n",
        "\n",
        "    print(\"Data from the Excel file:\")\n",
        "    print(spc)  # Display the first few rows of the DataFrame\n",
        "    return spc\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred while reading the Excel file: {e}\")\n",
        "\n",
        "\n",
        "def process_SPC(url, file_name, folder_id):\n",
        "  file_io = download_file_from_url(url)\n",
        "  if file_io:\n",
        "    file_io.seek(0)\n",
        "    file_id = upload_to_drive(file_io, file_name, folder_id)\n",
        "\n",
        "    if file_id:\n",
        "      uploaded_file_io = read_file_from_drive(file_id)\n",
        "      if uploaded_file_io:\n",
        "        processed_data = process_excel_SPC(uploaded_file_io)\n",
        "        return processed_data\n",
        "    else:\n",
        "        print(\"Download failed. The file will not be processed.\")\n",
        "\n",
        "def authenticate_gspread():\n",
        "    try:\n",
        "        service_account_content = \"\"\"\n",
        "        {\n",
        "          \"type\": \"service_account\",\n",
        "          \"project_id\": \"amigovetscript\",\n",
        "          \"private_key_id\": \"6858c4eaf9154d6504eebe4b30664b0ee68b8338\",\n",
        "          \"private_key\": \"-----BEGIN PRIVATE KEY-----\\\\nMIIEvAIBADANBgkqhkiG9w0BAQEFAASCBKYwggSiAgEAAoIBAQCM8fUIs0RlQ7AN\\\\noeJSNiJ1E1fiX2HvdplFAV3y8Uq0nokhLCZipUt+eWHkMpJFhAzWSO9AJK57u/3G\\\\nE6tYB6PuKmOc8Vq5lyOBv5qWVhVUJd323ZswnHhE6GQy63b6jCIwFWrw8WB+uo3H\\\\nC7TUlQkYd3D9xwjSuiHmhBDauZ9Unp0nmH17ymlt8PGELIGhPvb2gfGZAInBLr3W\\\\nzCPwbdDOFUKc+rIOQhz9f9bkcgzINLL4zdjQeCav6b2lMlrshgbLqwv2YQeAJL38\\\\nzrtEsORd2h04XLe2RLtTt9sThGfsyL5hgot2r+tMU5/wm9VEQPl1luiTNTpwwA64\\\\nJh0c/5AfAgMBAAECggEAK2i/36Ca0ZdxyxkPQ+PBZA6DlEhtONvto7eikFbpe8yS\\\\nDoHzBpHDOR44XJiIvVlIvNy0tyw1Aw3owI9BR/j+b7VlfapGF3/poyX4fhHgOsz4\\\\n2nXxPJ0MW6i5Z4dm2w663tVR3QhygEWDsgi0dn66UOtEhRy+ZmyGUWFecYcW/+/v\\\\nDc77fsr3RS3fgUTKV+Z3Dw6LmGwI2FeuunFyJvme3uRFvkgkxX5aBqX1OSJf+M+g\\\\nVGvZbW1VQ8Wp3X1V8+WLyDMbWDBRqi0Ccw4ePCszR1J1bx6MXZPNchbbGsparwi2\\\\nBzLO6BJeO6iu6P9McXdvZaPc+yGzp55vWgcRIHZ1/QKBgQDB53BYVswE2AhhzZ2v\\\\n0yh0DivBbX+8PBLle/15rL86v4pEUSDdcNGIc1sORXWLG0tY3X7biHwa6JynsG+l\\\\nw5x2buPSSRaJrZfd0MFdRMlvBKeNerw4pm2LRxGnRxAF9hDqp3eJacCYerxTwWAt\\\\nl2Izv4z9rlezX50hdIHJZrkD7QKBgQC6FNzpeu2JUe6dfCyeuMoNaxc6UrYCzYQC\\\\nfG1+OuIC5vN+Qr71/rKiD0ifAceCYIIFlIlnIUdxqoL5Xd5OfOywIVWcRVOMjChN\\\\n4rMA49zjRY4MC7qkfOFqjrWl1GNrY30ivJNJFutTEnCzzWTLBPllSaJDoxOI1qdr\\\\njkAseg46uwKBgFG8p8T1QadBEbd4n2IAlurlFljBObk1cZm+/IiP40R2fWhy8nGm\\\\nHw1v4xBPA0+SP97D77fG/tmw+GhPnaC4pnneILcCDDgZLw1X9ErGtkrQIXkoJbOT\\\\npFWzraNf90csBNGFqoQISiF8i2qa91oAmGrL8jj1hw6b3Xa+z/8ACDm5AoGAKZZ2\\\\nFPxzUChukuXotwSHq94OT+uiYBf8c+3JLtgMISfqrYJPWX02AUA3M8pbA4l8JbEf\\\\n0FvAsuev4/mVsKb84xRgJM/dr2C3tUiARyel+2lVKN4KNa7vVjhU4p4IJj0S/4tz\\\\nw3cK2wMZCyZRa4pODtQZHtK4j/Ghc0lUkFwrB/cCgYAHAQVxYZ92X1FMh2IQsenh\\\\nxnMEflMcdWpPj3g3lbs+lom3tY2AzjJTTRv5Y3HfuWFmLfnd+qQdn7UFDRJzsx1x\\\\nwRI2RR5CpN6EtT8SCHVkU+17p7jo/rX58LYzRipCOli+4+Uj1Wb/oZv5v0jtHRDA\\\\n12p5iu1uZrwJsFSza133jA==\\\\n-----END PRIVATE KEY-----\\\\n\",\n",
        "          \"client_email\": \"colab-automation-service-accou@amigovetscript.iam.gserviceaccount.com\",\n",
        "          \"client_id\": \"102973400010219708663\",\n",
        "          \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
        "          \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
        "          \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
        "          \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/colab-automation-service-accou%40amigovetscript.iam.gserviceaccount.com\",\n",
        "          \"universe_domain\": \"googleapis.com\"\n",
        "        }\n",
        "        \"\"\"\n",
        "\n",
        "        os.environ[\"SERVICE_ACCOUNT_JSON\"] = service_account_content\n",
        "        service_account_data = json.loads(os.environ[\"SERVICE_ACCOUNT_JSON\"])\n",
        "        with open(\"service_account.json\", \"w\") as json_file:\n",
        "            json.dump(service_account_data, json_file)\n",
        "\n",
        "        SERVICE_ACCOUNT_FILE = \"service_account.json\"\n",
        "\n",
        "        # Define the required scopes\n",
        "        SCOPES = [\n",
        "            \"https://www.googleapis.com/auth/spreadsheets\",\n",
        "            \"https://www.googleapis.com/auth/drive\"\n",
        "        ]\n",
        "\n",
        "        # Authenticate using the service account\n",
        "        credentials = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
        "        gc = gspread.authorize(credentials)\n",
        "        return gc\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during authentication: {e}\")\n",
        "        raise\n",
        "\n",
        "def build_drive_service():\n",
        "    try:\n",
        "        # Service account JSON content\n",
        "        service_account_content = \"\"\"\n",
        "        {\n",
        "          \"type\": \"service_account\",\n",
        "          \"project_id\": \"amigovetscript\",\n",
        "          \"private_key_id\": \"6858c4eaf9154d6504eebe4b30664b0ee68b8338\",\n",
        "          \"private_key\": \"-----BEGIN PRIVATE KEY-----\\\\nMIIEvAIBADANBgkqhkiG9w0BAQEFAASCBKYwggSiAgEAAoIBAQCM8fUIs0RlQ7AN\\\\noeJSNiJ1E1fiX2HvdplFAV3y8Uq0nokhLCZipUt+eWHkMpJFhAzWSO9AJK57u/3G\\\\nE6tYB6PuKmOc8Vq5lyOBv5qWVhVUJd323ZswnHhE6GQy63b6jCIwFWrw8WB+uo3H\\\\nC7TUlQkYd3D9xwjSuiHmhBDauZ9Unp0nmH17ymlt8PGELIGhPvb2gfGZAInBLr3W\\\\nzCPwbdDOFUKc+rIOQhz9f9bkcgzINLL4zdjQeCav6b2lMlrshgbLqwv2YQeAJL38\\\\nzrtEsORd2h04XLe2RLtTt9sThGfsyL5hgot2r+tMU5/wm9VEQPl1luiTNTpwwA64\\\\nJh0c/5AfAgMBAAECggEAK2i/36Ca0ZdxyxkPQ+PBZA6DlEhtONvto7eikFbpe8yS\\\\nDoHzBpHDOR44XJiIvVlIvNy0tyw1Aw3owI9BR/j+b7VlfapGF3/poyX4fhHgOsz4\\\\n2nXxPJ0MW6i5Z4dm2w663tVR3QhygEWDsgi0dn66UOtEhRy+ZmyGUWFecYcW/+/v\\\\nDc77fsr3RS3fgUTKV+Z3Dw6LmGwI2FeuunFyJvme3uRFvkgkxX5aBqX1OSJf+M+g\\\\nVGvZbW1VQ8Wp3X1V8+WLyDMbWDBRqi0Ccw4ePCszR1J1bx6MXZPNchbbGsparwi2\\\\nBzLO6BJeO6iu6P9McXdvZaPc+yGzp55vWgcRIHZ1/QKBgQDB53BYVswE2AhhzZ2v\\\\n0yh0DivBbX+8PBLle/15rL86v4pEUSDdcNGIc1sORXWLG0tY3X7biHwa6JynsG+l\\\\nw5x2buPSSRaJrZfd0MFdRMlvBKeNerw4pm2LRxGnRxAF9hDqp3eJacCYerxTwWAt\\\\nl2Izv4z9rlezX50hdIHJZrkD7QKBgQC6FNzpeu2JUe6dfCyeuMoNaxc6UrYCzYQC\\\\nfG1+OuIC5vN+Qr71/rKiD0ifAceCYIIFlIlnIUdxqoL5Xd5OfOywIVWcRVOMjChN\\\\n4rMA49zjRY4MC7qkfOFqjrWl1GNrY30ivJNJFutTEnCzzWTLBPllSaJDoxOI1qdr\\\\njkAseg46uwKBgFG8p8T1QadBEbd4n2IAlurlFljBObk1cZm+/IiP40R2fWhy8nGm\\\\nHw1v4xBPA0+SP97D77fG/tmw+GhPnaC4pnneILcCDDgZLw1X9ErGtkrQIXkoJbOT\\\\npFWzraNf90csBNGFqoQISiF8i2qa91oAmGrL8jj1hw6b3Xa+z/8ACDm5AoGAKZZ2\\\\nFPxzUChukuXotwSHq94OT+uiYBf8c+3JLtgMISfqrYJPWX02AUA3M8pbA4l8JbEf\\\\n0FvAsuev4/mVsKb84xRgJM/dr2C3tUiARyel+2lVKN4KNa7vVjhU4p4IJj0S/4tz\\\\nw3cK2wMZCyZRa4pODtQZHtK4j/Ghc0lUkFwrB/cCgYAHAQVxYZ92X1FMh2IQsenh\\\\nxnMEflMcdWpPj3g3lbs+lom3tY2AzjJTTRv5Y3HfuWFmLfnd+qQdn7UFDRJzsx1x\\\\nwRI2RR5CpN6EtT8SCHVkU+17p7jo/rX58LYzRipCOli+4+Uj1Wb/oZv5v0jtHRDA\\\\n12p5iu1uZrwJsFSza133jA==\\\\n-----END PRIVATE KEY-----\\\\n\",\n",
        "          \"client_email\": \"colab-automation-service-accou@amigovetscript.iam.gserviceaccount.com\",\n",
        "          \"client_id\": \"102973400010219708663\",\n",
        "          \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
        "          \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
        "          \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
        "          \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/colab-automation-service-accou%40amigovetscript.iam.gserviceaccount.com\"\n",
        "        }\n",
        "        \"\"\"\n",
        "\n",
        "        # Save JSON to a file\n",
        "        with open(\"service_account.json\", \"w\") as json_file:\n",
        "            json_file.write(service_account_content)\n",
        "\n",
        "        # Path to the JSON file\n",
        "        SERVICE_ACCOUNT_FILE = \"service_account.json\"\n",
        "\n",
        "        # Define the required scopes\n",
        "        SCOPES = [\"https://www.googleapis.com/auth/drive\"]\n",
        "\n",
        "        # Authenticate with the service account\n",
        "        credentials = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
        "        drive_service = build(\"drive\", \"v3\", credentials=credentials)\n",
        "\n",
        "        print(\"Drive service built successfully.\")\n",
        "        return drive_service\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while building the Drive service: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def write_dataframe_to_google_sheet(df, spreadsheet_id, gid, range_):\n",
        "  try:\n",
        "    gc = authenticate_gspread()\n",
        "    spreadsheet = gc.open_by_key(spreadsheet_id)\n",
        "    worksheet = spreadsheet.get_worksheet_by_id(gid)  # Using gid to get the specific worksheet\n",
        "    worksheet.batch_clear([range_])\n",
        "\n",
        "    # Write the DataFrame to the worksheet\n",
        "    set_with_dataframe(worksheet, df, row=1, col=1, include_index=False, include_column_header=True, resize=False)\n",
        "    print(\"Data is written successfully!\")\n",
        "  except Exception as e:\n",
        "        print(f\"An error occurred while writing to dataframe: {e}\")\n",
        "\n",
        "\n",
        "#SZR\n",
        "def process_corrupted_excel_file(file_io, drive_service, folder_id):\n",
        "    file_io.seek(0)\n",
        "    with zipfile.ZipFile(file_io) as excel_container:\n",
        "        shared_strings_path = 'xl/SharedStrings.xml'\n",
        "\n",
        "        if shared_strings_path in excel_container.namelist():\n",
        "            modified_stream = BytesIO()\n",
        "            with zipfile.ZipFile(modified_stream, 'w') as new_zip:\n",
        "                for item in excel_container.namelist():\n",
        "                    if item == shared_strings_path:\n",
        "                        with excel_container.open(item) as wrong_file:\n",
        "                            new_zip.writestr('xl/sharedStrings.xml', wrong_file.read())\n",
        "                    else:\n",
        "                        new_zip.writestr(item, excel_container.read(item))\n",
        "            modified_stream.seek(0)\n",
        "\n",
        "            file_id = upload_to_drive(modified_stream, \"SZR.xlsx\", folder_id)\n",
        "            return file_id\n",
        "        else:\n",
        "            print(\"SharedStrings.xml file not found in the archive.\")\n",
        "\n",
        "def process_excel_SZR(file_io):\n",
        "    try:\n",
        "        columns_to_read = ['Kod1C', 'Name', 'AvailabilityKolon', 'PriceRR']\n",
        "        dtype = {\n",
        "            'Kod1C': str,\n",
        "            'Name': str,\n",
        "            'AvailabilityKolon': str,\n",
        "        }\n",
        "\n",
        "        file_io.seek(0)\n",
        "        szr = pd.read_excel(file_io,\n",
        "                           dtype = dtype,\n",
        "                           usecols=columns_to_read,\n",
        "                           engine='openpyxl')\n",
        "        szr.rename(columns={\n",
        "            'Kod1C': 'vendor_code',\n",
        "            'Name': 'name',\n",
        "            'AvailabilityKolon': 'availability',\n",
        "            'PriceRR': 'price'\n",
        "        }, inplace=True)\n",
        "\n",
        "        szr['price'] = szr['price'].fillna(0)\n",
        "\n",
        "        szr['stock_status'] = szr['availability'].apply(lambda x: 'outofstock' if x == '-' else 'instock')\n",
        "\n",
        "        print(\"Data from the Excel file:\")\n",
        "        print(szr)  # Display the first few rows of the DataFrame\n",
        "        return szr\n",
        "\n",
        "    except ValueError as ve:\n",
        "        print(f\"ValueError: {ve}\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"The specified file was not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the Excel file: {e}\")\n",
        "\n",
        "def process_SZR_link(folder_id, file_url):\n",
        "    file_io = download_file_from_url(file_url)\n",
        "    if file_io:\n",
        "        file_io.seek(0)\n",
        "        file_id = upload_to_drive(file_io, \"SZR_preprocessed.xlsx\", folder_id)\n",
        "    file_pr = read_file_from_drive(file_id)\n",
        "    file_id_proc = process_corrupted_excel_file(file_pr, drive_service, folder_id)\n",
        "\n",
        "    file_io = read_file_from_drive(file_id_proc)\n",
        "    if file_io:\n",
        "        file_io.seek(0)\n",
        "        processed_data = process_excel_SZR(file_io)\n",
        "        delete_old_files(\"SZR_preprocessed.xlsx\", folder_id)\n",
        "        return processed_data\n",
        "    else:\n",
        "        print(\"Processing failed. The file will not be processed.\")\n",
        "\n",
        "def get_specific_cells(spreadsheet_id, gid,):\n",
        "    gc = authenticate_gspread()\n",
        "    spreadsheet = gc.open_by_key(spreadsheet_id)\n",
        "    worksheet = spreadsheet.get_worksheet_by_id(gid)  # Using gid to get the specific worksheet\n",
        "\n",
        "    cell_mapping = {\n",
        "        \"det\": \"B2\",\n",
        "        \"url_ntp\": \"B3\",\n",
        "        \"url_trp\": \"B4\",\n",
        "        \"url_vs\": \"B5\",\n",
        "        \"spreadsheet_id_bio\": \"B6\",\n",
        "        \"spreadsheet_id_oven\": \"B7\",\n",
        "        \"gid_bio\": \"C6\",\n",
        "        \"gid_oven\": \"C7\",\n",
        "        \"hill\": \"B8\",\n",
        "        \"alfa\": \"B9\",\n",
        "        \"mg\": \"B10\",\n",
        "        \"vm\": \"B11\",\n",
        "        \"url_szr\": \"B12\",\n",
        "        \"nstl\": \"B13\",\n",
        "        \"url_spc\": \"B14\",\n",
        "        \"szr\": \"B15\",\n",
        "        \"url_apg\": \"B16\",\n",
        "        \"vb1\": \"B17\",\n",
        "        \"dg\": \"B18\",\n",
        "        \"rcf\": \"B19\",\n",
        "        \"vb2\": \"B20\",\n",
        "        \"spreadsheet_id_simua\": \"B22\",\n",
        "        \"gid_simua\": \"C22\",\n",
        "        \"pimx\": \"B23\",\n",
        "    }\n",
        "\n",
        "    config = {}\n",
        "    for key, cell in cell_mapping.items():\n",
        "        config[key] = worksheet.acell(cell).value  # Get the value from the specific cell\n",
        "\n",
        "    return config\n",
        "\n",
        "def fetch_yml_data(url):\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        root = ET.fromstring(response.content)\n",
        "\n",
        "        catalog_date = root.get(\"date\")\n",
        "        offers = []\n",
        "\n",
        "        for offer in root.findall(\".//offer\"):\n",
        "            offer_data = {\n",
        "                'id': offer.attrib['id'],\n",
        "                'name': get_element_text(offer, 'name'),\n",
        "                'price': get_element_text(offer, 'price'),\n",
        "                'quantity_in_stock': get_element_text(offer, 'quantity_in_stock'),\n",
        "                'vendorCode': get_element_text(offer, 'vendorCode'),\n",
        "            }\n",
        "            offers.append(offer_data)\n",
        "\n",
        "        return catalog_date, offers\n",
        "    else:\n",
        "        print(f\"Failed to retrieve the YML file. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "# Function to safely get the text content of an XML element\n",
        "def get_element_text(element, tag_name):\n",
        "    tag = element.find(tag_name)\n",
        "    return tag.text if tag is not None else ''\n",
        "\n",
        "def convert_xls_to_xlsx(file_stream):\n",
        "    try:\n",
        "        # Read the .xls file with xlrd, without involving pandas\n",
        "        xls_workbook = xlrd.open_workbook(file_contents=file_stream.read())\n",
        "        xlsx_stream = BytesIO()\n",
        "\n",
        "        # Create a new .xlsx workbook with openpyxl\n",
        "        xlsx_workbook = Workbook()\n",
        "\n",
        "        for sheet_index in range(xls_workbook.nsheets):\n",
        "            xls_sheet = xls_workbook.sheet_by_index(sheet_index)\n",
        "\n",
        "            # Add a new sheet with the same name\n",
        "            if sheet_index == 0:  # Use the first sheet as the active one\n",
        "                xlsx_sheet = xlsx_workbook.active\n",
        "                xlsx_sheet.title = xls_sheet.name\n",
        "            else:\n",
        "                xlsx_sheet = xlsx_workbook.create_sheet(title=xls_sheet.name)\n",
        "\n",
        "            # Transfer cell data from .xls to .xlsx\n",
        "            for row_idx in range(xls_sheet.nrows):\n",
        "                for col_idx in range(xls_sheet.ncols):\n",
        "                    cell_value = xls_sheet.cell_value(row_idx, col_idx)\n",
        "                    xlsx_sheet.cell(row=row_idx + 1, column=col_idx + 1, value=cell_value)\n",
        "\n",
        "        # Save the .xlsx content to the in-memory stream\n",
        "        xlsx_workbook.save(xlsx_stream)\n",
        "        xlsx_stream.seek(0)  # Reset stream position\n",
        "\n",
        "        return xlsx_stream  # Return the .xlsx file stream\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during conversion: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_corrupted_excel_file(file_io, drive_service, folder_id):\n",
        "    file_io.seek(0)  # Reset the stream position\n",
        "    with zipfile.ZipFile(file_io) as excel_container:\n",
        "        # Step 3: Extract to a BytesIO object\n",
        "        shared_strings_path = 'xl/SharedStrings.xml'\n",
        "\n",
        "        # Check if the file exists and rename if necessary\n",
        "        if shared_strings_path in excel_container.namelist():\n",
        "            # We create a new BytesIO to hold the modified zip content\n",
        "            modified_stream = BytesIO()\n",
        "            with zipfile.ZipFile(modified_stream, 'w') as new_zip:\n",
        "                for item in excel_container.namelist():\n",
        "                    if item == shared_strings_path:\n",
        "                        # Read the wrong file and write it correctly\n",
        "                        with excel_container.open(item) as wrong_file:\n",
        "                            new_zip.writestr('xl/sharedStrings.xml', wrong_file.read())\n",
        "                    else:\n",
        "                        new_zip.writestr(item, excel_container.read(item))\n",
        "            modified_stream.seek(0)  # Reset the stream position for upload\n",
        "\n",
        "            # Step 4: Upload back to Google Drive\n",
        "            file_id = upload_to_drive(modified_stream, \"SZR.xlsx\", folder_id)\n",
        "            return file_id\n",
        "        else:\n",
        "            print(\"SharedStrings.xml file not found in the archive.\")\n",
        "\n",
        "def process_excel_SZR_upd(file_io):\n",
        "    try:\n",
        "        szr = pd.read_excel(file_io, skiprows = 10,\n",
        "                           engine='openpyxl')\n",
        "        szr = szr.drop(szr.columns[-1], axis=1)\n",
        "        szr = szr.iloc[:, [0, 14, 13, 18, 19]]\n",
        "        szr.columns = ['name', 'code', 'vendor_code', 'price', 'availability']\n",
        "        szr.dropna(subset=['code'], inplace=True)\n",
        "        szr.dropna(subset=['availability'], inplace=True)\n",
        "\n",
        "        szr['availability'] = szr['availability'].fillna(0)\n",
        "        szr['price'] = szr['price'].fillna(0)\n",
        "        szr['stock_status'] =  szr['availability'].apply(lambda x: 'instock' if x != '-' else 'outofstock')\n",
        "\n",
        "        szr = szr.drop('code', axis=1)\n",
        "\n",
        "        print(\"Data from the Excel file:\")\n",
        "        print(szr)  # Display the first few rows of the DataFrame\n",
        "        return szr\n",
        "\n",
        "    except ValueError as ve:\n",
        "        print(f\"ValueError: {ve}\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"The specified file was not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the Excel file: {e}\")\n",
        "\n",
        "def process_SZR_upd(folder_id, file_name):\n",
        "    file_io = read_file_from_drive_by_name(file_name, folder_id)\n",
        "    if file_io:\n",
        "      file_io.seek(0)\n",
        "      processed_data = process_excel_SZR_upd(file_io)\n",
        "      return processed_data\n",
        "    else:\n",
        "      print(\"Download failed. The file will not be processed.\")\n",
        "\n",
        "def process_excel_APG(file_io):\n",
        "    try:\n",
        "        apg = pd.read_excel(file_io, skiprows = 9,\n",
        "                           engine='openpyxl')\n",
        "        apg = apg.drop(apg.columns[-1], axis=1)\n",
        "        apg = apg.iloc[:, [1, 2, 7, 5]]\n",
        "        apg.columns = ['name', 'vendor_code', 'price', 'availability']\n",
        "        apg.dropna(subset=['availability'], inplace=True)\n",
        "        apg['vendor_code'] = 'APG' + apg['vendor_code']\n",
        "\n",
        "        apg['availability'] = apg['availability'].fillna(0)\n",
        "        apg['price'] = apg['price'].fillna(0)\n",
        "        apg['stock_status'] =  apg['availability'].apply(lambda x: 'outofstock' if x == 'немає' else 'instock')\n",
        "\n",
        "        print(\"Data from the Excel file:\")\n",
        "        print(apg)  # Display the first few rows of the DataFrame\n",
        "        return apg\n",
        "\n",
        "    except ValueError as ve:\n",
        "        print(f\"ValueError: {ve}\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"The specified file was not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the Excel file: {e}\")\n",
        "\n",
        "def process_APG(url, folder_id, file_name):\n",
        "    file_io = download_file_from_url(url)\n",
        "\n",
        "    if file_io:\n",
        "        file_io.seek(0)\n",
        "        file_id = upload_to_drive(file_io, file_name, folder_id)\n",
        "\n",
        "        if file_id:\n",
        "            uploaded_file_io = read_file_from_drive(file_id)\n",
        "\n",
        "            if uploaded_file_io:\n",
        "                processed_data = process_excel_APG(uploaded_file_io)\n",
        "                return processed_data\n",
        "    else:\n",
        "        print(\"Download failed. The file will not be processed.\")\n",
        "\n",
        "def process_excel_DG(file_io):\n",
        "    try:\n",
        "        raw_data = pd.read_excel(file_io, header=None)\n",
        "        relevant_columns = {\n",
        "            5: 'vendor_code',\n",
        "            3: 'name',\n",
        "            6: 'availability',\n",
        "            8: 'price'\n",
        "        }\n",
        "\n",
        "        dg = raw_data.iloc[0:, list(relevant_columns.keys())]\n",
        "        dg.columns = relevant_columns.values()\n",
        "\n",
        "        dg['vendor_code'] = 'DG' + dg['vendor_code']\n",
        "\n",
        "        dg = dg[dg['availability'].notna()]\n",
        "\n",
        "        dg['availability'] = pd.to_numeric(dg['availability'], errors='coerce')\n",
        "\n",
        "        dg['stock_status'] = dg['availability'].apply(lambda x: 'outofstock' if x == 0 else 'instock')\n",
        "\n",
        "        dg['price'] = dg['price'].fillna(0).infer_objects(copy=False)\n",
        "\n",
        "        print(\"Data from the DG file:\")\n",
        "        print(dg.head())  # Display the first few rows of the DataFrame\n",
        "\n",
        "        return dg\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing the Excel file: {e}\")\n",
        "\n",
        "def process_DG(folder_id, file_name):\n",
        "    if file_name.lower().endswith('.xls'):\n",
        "        # File is .xls, needs conversion\n",
        "        file_io = read_file_from_drive_by_name(file_name, folder_id)\n",
        "        if file_io:\n",
        "            file_iop = convert_xls_to_xlsx(file_io)\n",
        "            if file_iop:\n",
        "                file_iop.seek(0)\n",
        "                processed_data = process_excel_DG(file_iop)\n",
        "                return processed_data\n",
        "            else:\n",
        "                print(\"File conversion failed. The file will not be processed.\")\n",
        "                return None\n",
        "        else:\n",
        "            print(\"File not found in the specified folder.\")\n",
        "            return None\n",
        "    elif file_name.lower().endswith('.xlsx'):\n",
        "        # File is .xlsx, no conversion needed\n",
        "        file_io = read_file_from_drive_by_name(file_name, folder_id)\n",
        "        if file_io:\n",
        "            file_io.seek(0)\n",
        "            processed_data = process_excel_DG(file_io)\n",
        "            return processed_data\n",
        "        else:\n",
        "            print(\"File not found in the specified folder.\")\n",
        "            return None\n",
        "    else:\n",
        "        # Unsupported file format\n",
        "        print(\"Unsupported file format. Only .xls and .xlsx files are supported.\")\n",
        "        return None\n",
        "\n",
        "#VB\n",
        "def process_excel_VB(file_io):\n",
        "    try:\n",
        "        # Read as object (string) to prevent automatic conversion\n",
        "        vb = pd.read_excel(file_io, engine='openpyxl', header=1, dtype=str)\n",
        "\n",
        "        # Rename columns properly\n",
        "        vb.rename(columns={\n",
        "            'Unnamed: 3': 'vendor_code',\n",
        "            'Unnamed: 1': 'name',\n",
        "            'Unnamed: 6': 'price',\n",
        "            'Unnamed: 2': 'availability'\n",
        "        }, inplace=True)\n",
        "\n",
        "        expected_columns = ['vendor_code', 'name', 'price', 'availability']\n",
        "        vb = vb[expected_columns]\n",
        "\n",
        "        vb['vendor_code'] = vb['vendor_code'].astype(str).str.strip()\n",
        "        vb['vendor_code'] = vb['vendor_code'].apply(lambda x: x.rstrip('.0') if '.' in x else x)\n",
        "        vb['vendor_code'] = 'VB' + vb['vendor_code']\n",
        "\n",
        "        vb['price'] = pd.to_numeric(vb['price'], errors='coerce').fillna(0)\n",
        "\n",
        "        vb['stock_status'] = vb['availability'].apply(map_stock_level_vb)\n",
        "        vb = vb[~vb['stock_status'].str.contains(\"Unknown\", na=False)]\n",
        "        vb = vb[vb['availability'].notna()]\n",
        "        vb = vb.infer_objects()\n",
        "\n",
        "        print(\"Data from the Excel file:\")\n",
        "        print(vb.head())\n",
        "        return vb\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the Excel file: {e}\")\n",
        "\n",
        "def map_stock_level_vb(symbol):\n",
        "    if symbol == '# # #':\n",
        "        return 'instock'\n",
        "    elif symbol == '# #':\n",
        "        return 'instock'\n",
        "    elif symbol == '#':\n",
        "        return 'instock'\n",
        "    elif symbol == '-':\n",
        "        return 'outofstock'\n",
        "    else:\n",
        "        return 'Unknown'\n",
        "\n",
        "def process_VB(folder_id, file_name):\n",
        "    if file_name.lower().endswith('.xls'):\n",
        "        # File is .xls, needs conversion\n",
        "        file_io = read_file_from_drive_by_name(file_name, folder_id)\n",
        "        if file_io:\n",
        "            file_iop = convert_xls_to_xlsx(file_io)\n",
        "            if file_iop:\n",
        "                file_iop.seek(0)\n",
        "                processed_data = process_excel_VB(file_iop)\n",
        "                return processed_data\n",
        "            else:\n",
        "                print(\"File conversion failed. The file will not be processed.\")\n",
        "                return None\n",
        "        else:\n",
        "            print(\"File not found in the specified folder.\")\n",
        "            return None\n",
        "    elif file_name.lower().endswith('.xlsx'):\n",
        "        # File is .xlsx, no conversion needed\n",
        "        file_io = read_file_from_drive_by_name(file_name, folder_id)\n",
        "        if file_io:\n",
        "            file_io.seek(0)\n",
        "            processed_data = process_excel_VB(file_io)\n",
        "            return processed_data\n",
        "        else:\n",
        "            print(\"File not found in the specified folder.\")\n",
        "            return None\n",
        "    else:\n",
        "        # Unsupported file format\n",
        "        print(\"Unsupported file format. Only .xls and .xlsx files are supported.\")\n",
        "        return None\n",
        "\n",
        "#RCF\n",
        "def process_quantity_csv(file_io):\n",
        "    try:\n",
        "        quantity_data = pd.read_csv(file_io, header=0, sep=',')\n",
        "\n",
        "        quantity_data.rename(columns={\n",
        "            quantity_data.columns[0]: 'vendor_code',\n",
        "            quantity_data.columns[3]: 'availability'\n",
        "        }, inplace=True)\n",
        "\n",
        "        quantity_data.drop(quantity_data.columns[[1, 2]], axis=1, inplace=True)\n",
        "\n",
        "        return quantity_data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing the quantity CSV file: {e}\")\n",
        "\n",
        "def download_data_RCF(url, folder_id, file_name):\n",
        "    file_io = download_file_from_url(url)\n",
        "\n",
        "    if file_io:\n",
        "        file_io.seek(0)\n",
        "        file_id = upload_to_drive(file_io, file_name, folder_id)\n",
        "\n",
        "        if file_id:\n",
        "            uploaded_file_io = read_file_from_drive(file_id)\n",
        "            csv_df = process_quantity_csv(uploaded_file_io)\n",
        "            return csv_df\n",
        "    else:\n",
        "        print(\"Download failed. The file will not be processed.\")\n",
        "\n",
        "def process_excel_RCF(file_io, csv_df):\n",
        "    try:\n",
        "        raw_data = pd.read_excel(file_io, header=None)\n",
        "\n",
        "        relevant_columns = {\n",
        "            1: 'name',\n",
        "            0: 'vendor_code',\n",
        "            7: 'price'\n",
        "        }\n",
        "\n",
        "        rcf = raw_data.iloc[2:, list(relevant_columns.keys())]\n",
        "        rcf.columns = relevant_columns.values()  # Rename columns\n",
        "        rcf['vendor_code'] = rcf['vendor_code'].astype(str)\n",
        "        csv_df['vendor_code'] = csv_df['vendor_code'].astype(str)\n",
        "        rcf = rcf[rcf['price'].notna()]\n",
        "\n",
        "        merged_df = pd.merge(rcf, csv_df, on='vendor_code', how='left')\n",
        "        merged_df['vendor_code'] = 'RCF' + merged_df['vendor_code'].astype(str)\n",
        "\n",
        "        merged_df['stock_status'] = merged_df['availability'].apply(lambda x: 'instock' if pd.notna(x) else 'outofstock')\n",
        "        merged_df = merged_df[merged_df['name'].notna()]\n",
        "        merged_df['price'] = merged_df['price'].fillna(0).infer_objects(copy=False)\n",
        "\n",
        "        print(\"Data from the merged file:\")\n",
        "        print(merged_df.head())  # Display the first few rows of the DataFrame\n",
        "\n",
        "        return merged_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing the Excel file: {e}\")\n",
        "\n",
        "def process_RCF(folder_id, file_name, url, folder_id_auto, file_name_rcf):\n",
        "    file_io = read_file_from_drive_by_name(file_name, folder_id)\n",
        "    if file_io:\n",
        "        file_io.seek(0)\n",
        "        df = download_data_RCF(url_rcf, folder_id_auto, file_name_rcf)\n",
        "        processed_data = process_excel_RCF(file_io, df)\n",
        "        return processed_data\n",
        "    else:\n",
        "        print(\"Download failed. The file will not be processed.\")\n",
        "\n",
        "def process_excel_SIMUA(file_io):\n",
        "  try:\n",
        "    data = pd.read_excel(file_io, header=None)\n",
        "    relevant_columns = {\n",
        "        0: 'vendor_code',\n",
        "        1: 'name',\n",
        "        6: 'price',\n",
        "        8: 'availability',\n",
        "        8: 'stock_status' }\n",
        "\n",
        "    simua = data.iloc[4:, list(relevant_columns.keys())]\n",
        "    simua.columns = ['vendor_code', 'name', 'price', 'availability']\n",
        "    simua['stock_status'] = simua['availability']\n",
        "    simua = simua[simua['vendor_code'].notna()]\n",
        "\n",
        "    print(\"Data from the merged file:\")\n",
        "    print(simua.head())  # Display the first few rows of the DataFrame\n",
        "    return simua\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred while reading the Excel file: {e}\")\n",
        "\n",
        "def process_SIMUA(spreadsheet_id, gid, folder_id, file_name):\n",
        "    file_io = download_google_sheet(spreadsheet_id, gid)\n",
        "\n",
        "    if file_io:\n",
        "        file_io.seek(0)\n",
        "        file_id = upload_to_drive(file_io, file_name, folder_id)\n",
        "\n",
        "        if file_id:\n",
        "            uploaded_file_io = read_file_from_drive(file_id)\n",
        "            if uploaded_file_io:\n",
        "                processed_data = process_excel_SIMUA(uploaded_file_io)\n",
        "                return processed_data\n",
        "    else:\n",
        "        print(\"Download failed. The file will not be processed.\")\n",
        "\n",
        "#PIMX\n",
        "def process_xml_PIMX(file_io):\n",
        "    \"\"\"Extracts specific data from an XML file.\"\"\"\n",
        "    try:\n",
        "        # Parse the XML file\n",
        "        tree = ET.parse(file_io)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        # List to store extracted data\n",
        "        offers = []\n",
        "\n",
        "        # Iterate through each <offer> element\n",
        "        for offer in root.findall(\".//offer\"):\n",
        "            code_2 = get_element_text(offer, \"code_2\")\n",
        "            prefixed_code = f\"PIMX{code_2}\" if code_2 else ''\n",
        "\n",
        "            stock_quantity = get_element_text(offer, \"qty\")\n",
        "            price = get_element_text(offer, \"rrc\")\n",
        "\n",
        "            # Clean price: Remove spaces, replace commas with dots\n",
        "            price = price.replace(\"\\xa0\", \"\").replace(\",\", \".\") if price else \"0\"\n",
        "\n",
        "            offer_data = {\n",
        "                'vendor_code': prefixed_code,\n",
        "                'name': get_element_text(offer, \"title\"),\n",
        "                'price': float(price) if price else 0.0,\n",
        "                'availability': int(stock_quantity) if stock_quantity else 0,\n",
        "            }\n",
        "            offers.append(offer_data)\n",
        "\n",
        "        # Create a DataFrame from the offers list\n",
        "        pimx = pd.DataFrame(offers)\n",
        "\n",
        "        pimx['name'] = pimx['name'].fillna(0)\n",
        "\n",
        "        pimx['stock_status'] = pimx['availability'].apply(lambda x: 'instock' if x > 0 else 'outofstock')\n",
        "\n",
        "        print(pimx)\n",
        "        return pimx  # Return the DataFrame\n",
        "\n",
        "    except ET.ParseError:\n",
        "        print(\"Error parsing the XML file.\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "def process_PIMX(ftp_host, ftp_user, ftp_pass, remote_file, local_file, file_name, folder_id):\n",
        "    ftp = FTP(ftp_host)\n",
        "    ftp.login(user=ftp_user, passwd=ftp_pass)\n",
        "\n",
        "    with open(local_file, \"wb\") as file:\n",
        "        ftp.retrbinary(f\"RETR {remote_file}\", file.write)\n",
        "\n",
        "    print(f\"Файл {local_file} успішно завантажено!\")\n",
        "    ftp.quit()\n",
        "\n",
        "    with open(local_file, \"rb\") as file_io:\n",
        "        file_id = upload_to_drive(file_io, file_name, folder_id)\n",
        "\n",
        "    if file_id:\n",
        "        uploaded_file_io = read_file_from_drive(file_id)\n",
        "\n",
        "        if uploaded_file_io:\n",
        "            processed_data = process_xml_PIMX(uploaded_file_io)\n",
        "            return processed_data\n",
        "\n",
        "    print(\"Processing failed.\")\n",
        "    return None\n",
        "\n",
        "def write_dataframe_to_google_sheet_to_cell(df, spreadsheet_id, gid, range_, col, row):\n",
        "  try:\n",
        "    # Authenticate\n",
        "    gc = authenticate_gspread()\n",
        "    spreadsheet = gc.open_by_key(spreadsheet_id)\n",
        "    worksheet = spreadsheet.get_worksheet_by_id(gid)  # Using gid to get the specific worksheet\n",
        "    worksheet.batch_clear([range_])\n",
        "\n",
        "    # Write the DataFrame to the worksheet\n",
        "    set_with_dataframe(worksheet, df, row=row, col=col, include_index=False, include_column_header=True, resize=False)\n",
        "    print(\"Data is written successfully!\")\n",
        "  except Exception as e:\n",
        "        print(f\"An error occurred while writing to dataframe: {e}\")\n",
        "\n",
        "################################################################################\n",
        "drive_service = build_drive_service()\n",
        "\n",
        "feed_url = \"https://amigovet.net/wp-content/uploads/woo-feed/custom/xml/uaa-2-2.xml\"\n",
        "url = 'https://amigovet.salesdrive.me/export/yml/export.yml?publicKey=xTOfdyvLAv4h37xnsXkHU9V4ocDyyCG9NUQyGJUqUX5uolVFQ6pST-AEoRevVt8b8IxC6'\n",
        "\n",
        "folder_id_manual = '1S0SCGlrfS-4qizqsaJwFB1y-rAZOOJnl'\n",
        "folder_id_auto = '1a_Hk1jctFanowqqzqNTzslDL6-cBR04F'\n",
        "file_name_bio = \"BIO.xlsx\"\n",
        "file_name_oven = \"Oven.xlsx\"\n",
        "file_name_ntp = \"NTP.xlsx\"\n",
        "file_name_trp = \"TRP.xml\"\n",
        "file_name_vs = \"VS.xlsx\"\n",
        "file_name_vm = \"price.xlsx\"\n",
        "file_name_apg = \"APG.xlsx\"\n",
        "file_name_spc = \"SPC.xlsx\"\n",
        "file_name_rcf = \"data_RCF.csv\"\n",
        "file_name_simua = \"SIMUA\"\n",
        "file_name_feed = \"uaa-2-2.xml\"\n",
        "ftp_host = \"kx446741.ftp.tools\"\n",
        "ftp_user = \"kx446741_Grinevich\"\n",
        "ftp_pass = \"Kokos2065!\"\n",
        "config = get_specific_cells('1zXiaqI7MJZ3vhuaW3w0pJ4P72YE1CMwzvEkWHBU2WiY', '328154595')\n",
        "url_rcf = 'https://docs.google.com/spreadsheets/d/1S5WFBIOnWQQgifzskdSJplDyC5YVw_Hv/gviz/tq?tqx=out:csv&gid=552568590&range=A1:D'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fgPOJh5G9An",
        "outputId": "b763c056-d1ab-4136-bf49-8e497db62680"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded successfully.\n",
            "Deleted old file: APG.xlsx (ID: 1tSokoFytlvHqwI_8PtXFoB8tOhHSwmUS)\n",
            "File uploaded to Google Drive with ID: 1ZJWVJz_f8pH4aEydwqysndGNrsgoBS9t\n",
            "Download 100% complete.\n",
            "Data from the Excel file:\n",
            "                                                   name    vendor_code  \\\n",
            "1         PETKIND БІФ ТРАЙП ФОРМУЛА консерва д/собак...     APGPk00570   \n",
            "2         PETKIND ВЕНІСОН ТРАЙП ФОРМУЛА консерва д/с...     APGPk00560   \n",
            "3         PETKIND ДАК ФОРМУЛА консерва монопротеїн д...     APGPk00520   \n",
            "4         PETKIND ЛАМБ ТРАЙП ФОРМУЛА консерва  д/соб...     APGPk00540   \n",
            "5         PETKIND РЕД МІТ ФОРМУЛА консерва д/собак з...     APGPk00580   \n",
            "...                                                 ...            ...   \n",
            "1188      DEXAS Форма для заморозки льоду Айс Куб си...    APGGCT1-432   \n",
            "1189      DEXAS Форма для заморозки льоду Айс Куб си...   APGGCT1-1795   \n",
            "1190      DEXAS Форма для заморозки льоду Айс-олоджи...        APGGCIT   \n",
            "1191      DEXAS Черпак нейлоновий 33,3см (чорний/сір...  APGGN9-25-432   \n",
            "1192      DEXAS Щіточка для випікання з трітану з до...     APGGB3-432   \n",
            "\n",
            "       price availability stock_status  \n",
            "1     248.75  В наявності      instock  \n",
            "2     248.75  В наявності      instock  \n",
            "3     248.75  В наявності      instock  \n",
            "4     248.75  В наявності      instock  \n",
            "5     248.75  В наявності      instock  \n",
            "...      ...          ...          ...  \n",
            "1188  564.79  В наявності      instock  \n",
            "1189  564.79  В наявності      instock  \n",
            "1190  513.44     Обмежено      instock  \n",
            "1191  359.10  В наявності      instock  \n",
            "1192  872.71  В наявності      instock  \n",
            "\n",
            "[1163 rows x 5 columns]\n",
            "Download 100% complete.\n",
            "Data from the Excel file:\n",
            "name             object\n",
            "price           float64\n",
            "vendor_code      object\n",
            "availability    float64\n",
            "stock_status     object\n",
            "dtype: object\n",
            "                                  name   price        vendor_code  \\\n",
            "2    Ексклюжн Едалт Біф Смол Брід 2 кг   922.0  Alfa8011259002945   \n",
            "3   Ексклюжн Едалт Біф Смол Брід 500 г   293.0  Alfa8011259002938   \n",
            "4    Ексклюжн Едалт Біф Смол Брід 7 кг  2360.0  Alfa8011259004529   \n",
            "5   Ексклюжн Едалт Лемб Смол Брід 2 кг   922.0  Alfa8011259002969   \n",
            "6  Ексклюжн Едалт Лемб Смол Брід 500 г   293.0  Alfa8011259002952   \n",
            "\n",
            "   availability stock_status  \n",
            "2         472.0      instock  \n",
            "3         577.0      instock  \n",
            "4           2.0   outofstock  \n",
            "5         812.0      instock  \n",
            "6        1206.0      instock  \n",
            "Google Sheet downloaded successfully.\n",
            "Deleted old file: BIO.xlsx (ID: 19thiMUC4_gSrAONpa_Pa1lqw0wm0s6dg)\n",
            "File uploaded to Google Drive with ID: 19M5hSUOzLVBl-ApKJj_CJ5GX7BzUXZ5q\n",
            "Download 100% complete.\n",
            "Processed DataFrame:\n",
            "                                                name   price  \\\n",
            "1   LANDOR Сухий корм для кошенят качка з рисом 2 кг   735.0   \n",
            "2  LANDOR Сухий корм для кошенят качка з рисом 10 кг  3381.0   \n",
            "3  LANDOR Сухий корм для котів, які живуть в прим...   751.0   \n",
            "4  LANDOR Сухий корм для котів, які живуть в прим...  3467.0   \n",
            "5  LANDOR Сухий корм для дорослих котів з чутливи...   742.0   \n",
            "\n",
            "        vendor_code availability stock_status  \n",
            "1  BIO8433022859585         <100      instock  \n",
            "2  BIO8433022859592         <300      instock  \n",
            "3  BIO8433022859615            0   outofstock  \n",
            "4  BIO8433022859622         <300      instock  \n",
            "5  BIO8433022859646         <300      instock  \n",
            "Download 100% complete.\n",
            "Data from the Excel file:\n",
            "        vendor_code                                               name  \\\n",
            "2  DET8410650151946  Advance Cat Chicken & Rice для дорослих котів ...   \n",
            "3  DET8410650151618  Advance Cat Chicken & Rice для дорослих котів ...   \n",
            "4  DET8410650151595  Advance Cat Chicken & Rice для дорослих котів ...   \n",
            "5  DET8410650589428  Advance Cat Chicken & Rice для дорослих котів ...   \n",
            "6  DET8410650151885   Advance Cat Kitten для кошенят з куркою (0,4 кг)   \n",
            "\n",
            "        availability   price stock_status  \n",
            "2  Немає в наявності   626.0   outofstock  \n",
            "3  Немає в наявності  4616.0   outofstock  \n",
            "4  Немає в наявності  1166.0   outofstock  \n",
            "5  Немає в наявності  2160.0   outofstock  \n",
            "6  Немає в наявності   179.0   outofstock  \n",
            "Download 100% complete.\n",
            "Data from the DG file:\n",
            "        vendor_code                                               name  \\\n",
            "5        DGШтрихкод                                                ТМЦ   \n",
            "9   DG6971883204240  Інтерактивна іграшка для ласощів Миша, колір б...   \n",
            "10  DG6971883204325  Інтерактивна іграшка для ласощів Яйце, колір к...   \n",
            "11  DG6971883204226  Інтерактивна іграшка смарт ошийник колір чорни...   \n",
            "15  DG5407007851195  GD Cat Kitten Lamb & Turkey 0,4 кг/ Грандорф я...   \n",
            "\n",
            "    availability price stock_status  \n",
            "5            NaN  Цена      instock  \n",
            "9           78.0  1037      instock  \n",
            "10          15.0  1885      instock  \n",
            "11          74.0  1141      instock  \n",
            "15         793.0   400      instock  \n",
            "Download 100% complete.\n",
            "Data from the Excel file:\n",
            "  vendor_code                                               name price  \\\n",
            "0  HILL605981  PD Feline C/D Mul Strs Курка-Стрес у кіш.,стру...   375   \n",
            "1  HILL605980  PD Feline C/D Mul Strs Курка-Стрес у кіш.,стру...  1163   \n",
            "2  HILL605949  PD Feline C/D Mul Strs Курка-Стрес у кіш.,стру...  2096   \n",
            "3  HILL605948  PD Feline C/D Mul Strs Курка-Стрес у кіш.,стру...  4966   \n",
            "4  HILL605891  PD Feline C/D-курка-Запобіг-ня струвітів, окса...   369   \n",
            "\n",
            "  availability stock_status  \n",
            "0                   instock  \n",
            "1                   instock  \n",
            "2                   instock  \n",
            "3                   instock  \n",
            "4                   instock  \n",
            "Download 100% complete.\n",
            "Data from the Excel file:\n",
            "                                             name      vendor_code  \\\n",
            "2   OASY DOG LIFESTAGE Puppy & Junior Small  1 кг  MG8053017348780   \n",
            "3   OASY DOG LIFESTAGE Puppy & Junior Small  3 кг  MG8053017348841   \n",
            "4  OASY DOG LIFESTAGE Puppy & Junior Small  18 кг  MG8053017349176   \n",
            "5   OASY DOG LIFESTAGE Puppy & Junior Medium 3 кг  MG8053017348865   \n",
            "6  OASY DOG LIFESTAGE Puppy & Junior Medium 18 кг  MG8053017349183   \n",
            "\n",
            "   availability   price stock_status  \n",
            "2           167   425.0      instock  \n",
            "3             0   815.0   outofstock  \n",
            "4            12  4020.0      instock  \n",
            "5             0   815.0   outofstock  \n",
            "6             3  4020.0   outofstock  \n",
            "File downloaded successfully.\n",
            "Deleted old file: NTP.xlsx (ID: 1uiw2S2nwyom5B5YU8297yyENt57fDnTi)\n",
            "File uploaded to Google Drive with ID: 1nj4OsrxSSaQXGZYM2ARGA3SQr2fxZAD8\n",
            "Download 100% complete.\n",
            "Data from the Excel file:\n",
            "   vendor_code                                               name  price  \\\n",
            "0  NTPNPS45763  Сухий корм для дорослих котів мешкаючих у буди...  209.0   \n",
            "1  NTPNPS45757  Сухий корм для кошенят Nature's Protection Kit...  176.0   \n",
            "2  NTPNPS45784  Сухий корм для дорослих котів великих порід Na...  696.0   \n",
            "3  NTPNPS45785  Сухий корм для кошенят великих порід Nature's ...  989.0   \n",
            "4  NTPNPS45760  Сухий корм для дорослих котів з довгою шерстю ...  195.0   \n",
            "\n",
            "  availability stock_status  \n",
            "0  В наявності      instock  \n",
            "1  В наявності      instock  \n",
            "2  В наявності      instock  \n",
            "3  В наявності      instock  \n",
            "4  В наявності      instock  \n",
            "Download 100% complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-1692290669>:760: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  nstl['price'] = nstl['price'].fillna(0).infer_objects(copy=False)\n",
            "<ipython-input-1-1692290669>:761: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  nstl['regular_avail'] = nstl['regular_avail'].fillna(0).infer_objects(copy=False)\n",
            "<ipython-input-1-1692290669>:762: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  nstl['promo_avail'] = nstl['promo_avail'].fillna(0).infer_objects(copy=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data from the Excel file:\n",
            "           vendor_code                                               name  \\\n",
            "2    NSTL8445290071880               ВАН ЕДАЛТ ДЛЯ КОТІВ КУРКА 10X450Г UA   \n",
            "3    NSTL8445290071972  Purina One(Пуріна Ван).Для Кошенят Курка&НЗерн...   \n",
            "4    NSTL8445290455277             ВАН БЕЗ ЗЕРН ДКОТ ДОР ЛОСОСЬ 6X600Г UA   \n",
            "5    NSTL8445290455857           ВАН БЕЗ ЗЕРН ДКОТ СТЕР ЯЛОВИЧИНА6X600ГUA   \n",
            "6    NSTL8445290067821  Purina One Indoor(ПурінаВан Індор).Для дом кот...   \n",
            "..                 ...                                                ...   \n",
            "298  NSTL8445290041074  ProPlan FORTIFLORA. Пробіотик для дорослих соб...   \n",
            "299  NSTL8445290507495  ProPlan FORTIFLORA Plus. Пробіотик для доросли...   \n",
            "300  NSTL8445290504937  ProPlan FORTIFLORA Plus. Пробіотик для доросли...   \n",
            "301  NSTL8445290041173  ProPlan FORTIFLORA. Пробіотик для дорослих кот...   \n",
            "302  NSTL8445290041210  ProPlan FORTIFLORA. Пробіотик для дорослих соб...   \n",
            "\n",
            "      price  availability stock_status  \n",
            "2      0.00             0   outofstock  \n",
            "3      0.00             0   outofstock  \n",
            "4      0.00             0   outofstock  \n",
            "5      0.00             0   outofstock  \n",
            "6      0.00             0   outofstock  \n",
            "..      ...           ...          ...  \n",
            "298  645.90             0   outofstock  \n",
            "299  774.15             0   outofstock  \n",
            "300  774.15             0   outofstock  \n",
            "301  167.05             0   outofstock  \n",
            "302  167.05             0   outofstock  \n",
            "\n",
            "[266 rows x 5 columns]\n",
            "Failed to download file. Status code: 401\n",
            "Download failed. The file will not be processed.\n",
            "File downloaded successfully.\n",
            "Deleted old file: SPC.xlsx (ID: 1-6zuL0LoHffgsDfFWWGrG-IEltQDpiQn)\n",
            "File uploaded to Google Drive with ID: 1tRC9f-75Y42GSgbg4lgqSLzBkHnphliy\n",
            "Download 100% complete.\n",
            "Data from the Excel file:\n",
            "      vendor_code                                               name   price  \\\n",
            "0        SPC00028  00028 1st Choice відро фірмове з візерунком 3,...   135.0   \n",
            "1       SPCФЧСВД2  1st Choice Adult Derma ФЕСТ ЧОЙС ДЕРМА сухий д...  1302.0   \n",
            "2      SPCФЧСВД12  1st Choice Adult Derma ФЕСТ ЧОЙС ДЕРМА сухий д...  7238.0   \n",
            "3     SPCФЧКВД1,8  1st Choice Adult Derma ФЕСТ ЧОЙС ДЕРМА сухий д...   903.0   \n",
            "4     SPCФЧКВД320  1st Choice Adult Derma ФЕСТ ЧОЙС ДЕРМА сухий д...   249.0   \n",
            "...           ...                                                ...     ...   \n",
            "3212    SPC800406  Who Cares WC Lavander ВІСІ ЛАВАНДА поглинальни...   240.0   \n",
            "3213    SPC800437  Who Cares WC Lavander ВІСІ ЛАВАНДА поглинальни...   443.0   \n",
            "3214    SPC297377  Woofaloo Dog Toilet ВУФАЛУ ТУАЛЕТ З ДЕРЕВОМ СТ...  2205.0   \n",
            "3215     SPC20040  ZenKitty Clumping Tofu Green Tea ЗЕН КІТТІ ТОФ...   399.0   \n",
            "3216     SPC20030  ZenKitty Clumping Tofu Lavender ЗЕН КІТТІ ТОФУ...   399.0   \n",
            "\n",
            "     availability stock_status  \n",
            "0              '+      instock  \n",
            "1              '-   outofstock  \n",
            "2              '+      instock  \n",
            "3              '-   outofstock  \n",
            "4              '+      instock  \n",
            "...           ...          ...  \n",
            "3212           '+      instock  \n",
            "3213           '+      instock  \n",
            "3214           '-   outofstock  \n",
            "3215           '+      instock  \n",
            "3216           '+      instock  \n",
            "\n",
            "[3217 rows x 5 columns]\n",
            "File downloaded successfully.\n",
            "No old files to delete.\n",
            "File uploaded to Google Drive with ID: 1l4dyZLWFXOnOPZ5TRPg1y8fZDXTrx6Ei\n",
            "Download 100% complete.\n",
            "Deleted old file: SZR.xlsx (ID: 1d560qqqs-dTGpi_82ZFU5lDCIopdQRCI)\n",
            "File uploaded to Google Drive with ID: 1dJ7bwf7RgPJh9LKcvEXA9vjOIjSw6tZi\n",
            "Download 100% complete.\n",
            "Data from the Excel file:\n",
            "     vendor_code                                               name   price  \\\n",
            "0     1111141376     Сіно лугове Природа для гризунів люцерна 200 г    66.0   \n",
            "1     1111142763  Brit Care Sensitive Venison and Potato 3 kg (д...  1132.0   \n",
            "2     1111142798  Корм Vitakraft Emotion для декоративних гризун...   455.0   \n",
            "3     1111142882                                      Ротор к FZN-3   438.0   \n",
            "4     1111142886  Вісь Aquael для ротора внутрішнього фільтру Tu...   190.0   \n",
            "...          ...                                                ...     ...   \n",
            "7703  1111139043  Ласощі Trixie Premio Chicken Pizza для собак п...   164.0   \n",
            "7704  1111139044  Ласощі Trixie Premio Tuna Sandwiches для котів...   122.0   \n",
            "7705  1111139045  Ласощі Trixie Premio Tuna Rolls для котів шмат...   122.0   \n",
            "7706  1111139047  Ласощі Trixie Premio Fishies для собак з рибою...   164.0   \n",
            "7707  1111139052  Двері Trixie Free для собак пластикові розмір ...  1753.0   \n",
            "\n",
            "     availability stock_status  \n",
            "0               -   outofstock  \n",
            "1               -   outofstock  \n",
            "2               +      instock  \n",
            "3               -   outofstock  \n",
            "4               +      instock  \n",
            "...           ...          ...  \n",
            "7703            +      instock  \n",
            "7704            +      instock  \n",
            "7705            +      instock  \n",
            "7706            +      instock  \n",
            "7707            +      instock  \n",
            "\n",
            "[7708 rows x 5 columns]\n",
            "Deleted old file: SZR_preprocessed.xlsx (ID: 1l4dyZLWFXOnOPZ5TRPg1y8fZDXTrx6Ei)\n",
            "File downloaded successfully.\n",
            "Deleted old file: TRP.xml (ID: 1Gt_0-CYvqS52cIi_xpMrB5FWj8TD5CZ6)\n",
            "File uploaded to Google Drive with ID: 1Ic0kR0ymi5yd0hQYWShSGuEprUFI7Opd\n",
            "Download 100% complete.\n",
            "     vendor_code                                               name   price  \\\n",
            "0       TRP37199                                                  0    0.00   \n",
            "1      TRP111982                                                  0    0.00   \n",
            "2      TRP112058  Колба Vitapol Smakers Box для німф, зі смаком ...  569.50   \n",
            "3      TRP112337                                                  0  546.00   \n",
            "4      TRP113008  Іграшка AnimAll Fun для собак, м&apos;яч Вкусн...   58.00   \n",
            "...          ...                                                ...     ...   \n",
            "7797    TRP27687                                                  0    0.00   \n",
            "7798    TRP27689                                                  0    0.00   \n",
            "7799    TRP27707       Щипці Resun AT-070 для посадки рослин, 70 см   73.00   \n",
            "7800    TRP47963  Акваріумна лампа Resun AquaSyncro LEDGT8-30W с...  793.92   \n",
            "7801    TRP47964  Акваріумна лампа Resun AquaSyncro LEDGT8-40W с...  984.06   \n",
            "\n",
            "      availability stock_status  \n",
            "0                0   outofstock  \n",
            "1                0   outofstock  \n",
            "2              100      instock  \n",
            "3                0   outofstock  \n",
            "4                0   outofstock  \n",
            "...            ...          ...  \n",
            "7797             0   outofstock  \n",
            "7798             0   outofstock  \n",
            "7799             0   outofstock  \n",
            "7800             0   outofstock  \n",
            "7801             0   outofstock  \n",
            "\n",
            "[7802 rows x 5 columns]\n",
            "Download 100% complete.\n",
            "Data from the Excel file:\n",
            "  vendor_code                                               name  price  \\\n",
            "2      VBA453          Антиоксидантна рідина для догляду за н...  745.0   \n",
            "3      VBH674          Антистатік Anti-Static Control, для ко...  721.0   \n",
            "4      VBH695          Багатофазний кондиціонер-спрей Mix Art...  842.0   \n",
            "5      VBH928          Відбілююча пудра для стриппінгу Powder...  733.0   \n",
            "6      VBH640          Гель Aurigel для очищення вух, з екстр...  699.0   \n",
            "\n",
            "  availability stock_status  \n",
            "2            #      instock  \n",
            "3            #      instock  \n",
            "4            #      instock  \n",
            "5            #      instock  \n",
            "6            #      instock  \n",
            "Download 100% complete.\n",
            "Data from the Excel file:\n",
            "  vendor_code                                               name   price  \\\n",
            "2    VB813300          Benebone Bacon Stick іграшка міцна для...  1019.0   \n",
            "3    VB812350          Benebone Bacon Stick іграшка міцна для...   744.0   \n",
            "4    VB811300          Benebone Bacon Stick іграшка міцна для...   621.0   \n",
            "5    VB890300          Benebone Dental Chew Bacon іграшка міц...  1019.0   \n",
            "6    VB860350          Benebone Dental Chew Bacon іграшка міц...   744.0   \n",
            "\n",
            "  availability stock_status  \n",
            "2            #      instock  \n",
            "3            #      instock  \n",
            "4            #      instock  \n",
            "5            #      instock  \n",
            "6            #      instock  \n",
            "File downloaded successfully.\n",
            "Deleted old file: VS.xlsx (ID: 1kYKTiuKmg789kYKb7cI4kPvI8fyrcdn5)\n",
            "File uploaded to Google Drive with ID: 1UC9mk9_WRXoIqZhx1sKvIrC8lNBczHNo\n",
            "Download 100% complete.\n",
            "Data from the Excel file:\n",
            "  vendor_code                                          name availability  \\\n",
            "0       VSnan  Преднізолон  таб. по 0,5 гр.1 блістер 20таб.          +++   \n",
            "2  VSMSD14652                    Бравекто 10-20кг 500мг MSD          +++   \n",
            "3  VSMSD14650                  Бравекто 2-4,5кг 112,5мг MSD          +++   \n",
            "4  VSMSD14653                   Бравекто 20-40кг 1000мг MSD          +++   \n",
            "5  VSMSD14651                   Бравекто 4,5-10кг 250мг MSD          +++   \n",
            "\n",
            "       price stock_status  \n",
            "0   186.4176      instock  \n",
            "2  1282.2600      instock  \n",
            "3  1138.8400      instock  \n",
            "4  1398.7000      instock  \n",
            "5  1218.3600      instock  \n",
            "Download 100% complete.\n",
            "Download failed. The file will not be processed. <_io.BytesIO object at 0x79792021aca0> 1a_Hk1jctFanowqqzqNTzslDL6-cBR04F price.xlsx\n",
            "Data from the Excel file:\n",
            "  vendor_code                                               name      price  \\\n",
            "0    VM003701             Буторфан, 10 мл + Медісон, 10 мл_Акція  1662.7690   \n",
            "1    VM003577  Сефорте для котів вагою 2,5 - 7,5 кг, 0,75 мл,...     0.0145   \n",
            "2    VM003578  Сефорте для котів вагою 7,5 - 10 кг, 1 мл, 1 п...     0.0145   \n",
            "3    VM003576  Сефорте для котів та собак до 2,5 кг, 0,25 мл,...     0.0145   \n",
            "4    VM003581  Сефорте для собак вагою 10 - 20 кг, 2 мл, 1 пі...     0.0145   \n",
            "\n",
            "  stock_status availability  \n",
            "0      instock    available  \n",
            "1      instock    available  \n",
            "2      instock    available  \n",
            "3      instock    available  \n",
            "4      instock    available  \n",
            "Processed data =      vendor_code                                               name  \\\n",
            "0       VM003701             Буторфан, 10 мл + Медісон, 10 мл_Акція   \n",
            "1       VM003577  Сефорте для котів вагою 2,5 - 7,5 кг, 0,75 мл,...   \n",
            "2       VM003578  Сефорте для котів вагою 7,5 - 10 кг, 1 мл, 1 п...   \n",
            "3       VM003576  Сефорте для котів та собак до 2,5 кг, 0,25 мл,...   \n",
            "4       VM003581  Сефорте для собак вагою 10 - 20 кг, 2 мл, 1 пі...   \n",
            "...          ...                                                ...   \n",
            "1161    VM000775                                 Мазь Санофіт, 50 г   \n",
            "1162    VM001033                                 Пресорб, 10 г № 20   \n",
            "1163    VM003673                              Протего спрей, 400 мл   \n",
            "1164    VM001542                            Тераміцин спрей, 150 мл   \n",
            "1166    VM002633  Переноска Gulliver 3, 61*40*38 см, пластикові ...   \n",
            "\n",
            "          price stock_status availability  \n",
            "0     1662.7690      instock    available  \n",
            "1        0.0145      instock    available  \n",
            "2        0.0145      instock    available  \n",
            "3        0.0145      instock    available  \n",
            "4        0.0145      instock    available  \n",
            "...         ...          ...          ...  \n",
            "1161    63.9450      instock    available  \n",
            "1162   300.7300      instock    available  \n",
            "1163  1088.2200      instock    available  \n",
            "1164   332.6300      instock    available  \n",
            "1166  1192.8000      instock    available  \n",
            "\n",
            "[1137 rows x 5 columns]\n",
            "Download 100% complete.\n",
            "File downloaded successfully.\n",
            "Deleted old file: data_RCF.csv (ID: 1sfgGZNU9cunJeRubtO-Dejq44yOGZrm0)\n",
            "File uploaded to Google Drive with ID: 1yLSRTh0oOdALVKCHkFbOnQc14vC4ITid\n",
            "Download 100% complete.\n",
            "Data from the merged file:\n",
            "                          name vendor_code   price   availability stock_status\n",
            "0   VHN F URINARY SO 3,5kg+12p    RCF11825  1920.0     більше 100      instock\n",
            "1  VHN F SKIN & COAT 3,5KG+12p    RCF11826  1780.0  від 10 до 100      instock\n",
            "2     VHN F GASTRO INT 4KG+12p    RCF11827  2285.0     більше 100      instock\n",
            "3   VHN F RENAL SELECT 4KG+12p    RCF11828  2280.0  від 10 до 100      instock\n",
            "4   VHN F MAT CONSULT 3,5K+12p    RCF11829  1690.0  від 10 до 100      instock\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-1692290669>:1625: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  merged_df['price'] = merged_df['price'].fillna(0).infer_objects(copy=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Sheet downloaded successfully.\n",
            "Deleted old file: SIMUA (ID: 1Iw9uTHFmn8uFedM7LKk7e0WSz_mi3TOz)\n",
            "File uploaded to Google Drive with ID: 1LNG40gCZtxDwCKwU1B8LpgwlK0qk0cHY\n",
            "Download 100% complete.\n",
            "Data from the merged file:\n",
            "    vendor_code                  name price availability stock_status\n",
            "7   SIMUA202241               Золетіл  1673     instock      instock \n",
            "8   SIMUA307139                Алізін  2215     instock      instock \n",
            "10  SIMUA308683             Кортаванс   931     instock      instock \n",
            "11  SIMUA307135                Ізотік   590     instock      instock \n",
            "12  SIMUA306934  Мілпро коти (4-8 кг)   587     instock      instock \n",
            "Файл GrinevichfXML.xml успішно завантажено!\n",
            "Deleted old file: Grinevichf_drive.xml (ID: 1lsNtcVol4NhBEShuCC0y9jCDswFzlUVA)\n",
            "File uploaded to Google Drive with ID: 12nfI-7JlchjQ2P1INGBREAIGhWrJqhPW\n",
            "Download 100% complete.\n",
            "            vendor_code                                               name  \\\n",
            "0     PIMX8594000256229                         Пакети д/риб (мин 25шт/уп)   \n",
            "1     PIMX8058093276477  Переноска  GIPSY XS smal Light Blue ,  пластик...   \n",
            "2     PIMX8058093276446  Переноска  GIPSY XS smal Light Green ,  пласти...   \n",
            "3     PIMX8058093276453  Переноска  GIPSY XS smal Lilla ,  пластикові д...   \n",
            "4     PIMX8058093276460  Переноска  GIPSY XS smal Yellow ,  пластикові ...   \n",
            "...                 ...                                                ...   \n",
            "4538  PIMX6930095837967  Щітка силіконова на руку,для вичіс.шерсті (рег...   \n",
            "4539  PIMX6930095837974  Щітка силіконована руку ,для вичіс. шерсті \"Пу...   \n",
            "4540  PIMX8023222064195      Щітка-пуходерка з напиленням нарукавна 3шт/уп   \n",
            "4541  PIMX8023222012134            Щітка-руковиця гумова, 19,5х12см 6шт/уп   \n",
            "4542  PIMX8022767038111           Щітка-щипці подвійна IvSanBernard Doppia   \n",
            "\n",
            "       price  availability stock_status  \n",
            "0       6.72             0   outofstock  \n",
            "1     393.12             2      instock  \n",
            "2     393.12             2      instock  \n",
            "3     393.12             2      instock  \n",
            "4     393.12             2      instock  \n",
            "...      ...           ...          ...  \n",
            "4538   69.84             2      instock  \n",
            "4539  102.06             2      instock  \n",
            "4540  409.56             2      instock  \n",
            "4541  321.42             2      instock  \n",
            "4542  953.70             1      instock  \n",
            "\n",
            "[4543 rows x 5 columns]\n",
            "asdfgh                                                     name vendor_code   price  \\\n",
            "2562                                                 ТМЦ  DGШтрихкод    Цена   \n",
            "2882   Набір 3 види сухого корму 400г для нестерилізо...         NaN    1065   \n",
            "11827  FHN EXIGENT SAVOUR 2kg + FHN WET INST in jelly...    RCF11995  1649.0   \n",
            "11830  FCN URINARY CARE 2kg + FHN WET URINARY CARE 12...    RCF11998  1890.0   \n",
            "11833                           SHN MEDIUM AD 12kg + 3kg    RCF11775  3060.0   \n",
            "11835                             SHN MAXI AD 12kg + 3kg    RCF11776  3060.0   \n",
            "11836                             SHN MINI ADULT 7kg+1kg    RCF11745  2345.0   \n",
            "11837                             SHN MINI PUPPY 7kg+1kg    RCF11744  2345.0   \n",
            "11839                        VHN F URINARY SO 7,5+1,5kg     RCF11939  4050.0   \n",
            "11844                       VHN C HEP Loaf Can 420G 10+2    RCF11949  1750.0   \n",
            "11845                     BHN YORKSHIRE PUPPY 1.2kg+300g    RCF11471   560.0   \n",
            "11947                                       BABYCAT MILK  RCF2553003  1065.0   \n",
            "12120                             ANALLERGENIC SMALL DOG  RCF3317030  1720.0   \n",
            "\n",
            "      availability stock_status  \n",
            "2562           NaN      instock  \n",
            "2882          17.0      instock  \n",
            "11827          NaN   outofstock  \n",
            "11830          NaN   outofstock  \n",
            "11833          NaN   outofstock  \n",
            "11835          NaN   outofstock  \n",
            "11836          NaN   outofstock  \n",
            "11837          NaN   outofstock  \n",
            "11839          NaN   outofstock  \n",
            "11844          NaN   outofstock  \n",
            "11845          NaN   outofstock  \n",
            "11947          NaN   outofstock  \n",
            "12120          NaN   outofstock  \n",
            "                                            name        vendor_code     price  \\\n",
            "0              Ексклюжн Едалт Біф Смол Брід 2 кг  Alfa8011259002945     922.0   \n",
            "1             Ексклюжн Едалт Біф Смол Брід 500 г  Alfa8011259002938     293.0   \n",
            "2              Ексклюжн Едалт Біф Смол Брід 7 кг  Alfa8011259004529    2360.0   \n",
            "3             Ексклюжн Едалт Лемб Смол Брід 2 кг  Alfa8011259002969     922.0   \n",
            "4            Ексклюжн Едалт Лемб Смол Брід 500 г  Alfa8011259002952     293.0   \n",
            "...                                          ...                ...       ...   \n",
            "36513      Розчин новокаїну 2% 200 мл /Фарматон/         VSFAR27780   66.9956   \n",
            "36514                 Стимул N 100 мл /Фарматон/         VSFAR09690    40.896   \n",
            "36515  Тілозомікол 5%,10 мл орал. Фарматон/Девіє         VSFAR09221    35.216   \n",
            "36516                  Тілоциклін №50 /Фарматон/              VSnan   56.6864   \n",
            "36517                    Тімокс 100 г /Фарматон/         VSFAR09361  154.5954   \n",
            "\n",
            "      availability stock_status  \n",
            "0            472.0      instock  \n",
            "1            577.0      instock  \n",
            "2              2.0   outofstock  \n",
            "3            812.0      instock  \n",
            "4           1206.0      instock  \n",
            "...            ...          ...  \n",
            "36513          +++      instock  \n",
            "36514            -   outofstock  \n",
            "36515          +++      instock  \n",
            "36516          +++      instock  \n",
            "36517          +++      instock  \n",
            "\n",
            "[36518 rows x 5 columns]\n",
            "            id                                               name  price  \\\n",
            "0     ФЧСЩММК7  Сухий суперпреміум корм для цуценят малих порі...    1.0   \n",
            "1   ФЧСЩММК350  Сухий суперпреміум корм для цуценят малих порі...    1.0   \n",
            "2  ФЧСЩММК2_72  Сухий суперпреміум корм для цуценят малих порі...    1.0   \n",
            "3    ФЧСВММЯР7  Сухий суперпреміум корм для собак міні та мали...    1.0   \n",
            "4  ФЧСВММЯР350  Сухий суперпреміум корм для собак міні та мали...    1.0   \n",
            "\n",
            "   quantity_in_stock   vendorCode stock_status_salesdrive      catalog_date  \n",
            "0                  0     ФЧСЩММК7              outofstock  2025-06-16 15:11  \n",
            "1                  0   ФЧСЩММК350              outofstock  2025-06-16 15:11  \n",
            "2                  0  ФЧСЩММК2_72              outofstock  2025-06-16 15:11  \n",
            "3                  0    ФЧСВММЯР7              outofstock  2025-06-16 15:11  \n",
            "4                  0  ФЧСВММЯР350              outofstock  2025-06-16 15:11  \n",
            "Data is written successfully!\n",
            "Data is written successfully!\n",
            "Data is written successfully!\n",
            "Data is written successfully!\n"
          ]
        }
      ],
      "source": [
        "apg = process_APG(config.get(\"url_apg\"), folder_id_auto, file_name_apg)\n",
        "alfa = process_Alfa(folder_id_manual, config.get(\"alfa\"))\n",
        "bio = process_BIO(config.get(\"spreadsheet_id_bio\"), config.get(\"gid_bio\"), folder_id_auto, file_name_bio)\n",
        "det = process_DET(folder_id_manual, config.get(\"det\"))\n",
        "dg = process_DG(folder_id_manual, config.get(\"dg\"))\n",
        "hill = process_HILL(folder_id_manual, config.get(\"hill\"))\n",
        "mg = process_MG(folder_id_manual, config.get(\"mg\"))\n",
        "ntp = process_NTP(config.get(\"url_ntp\"), folder_id_auto, file_name_ntp)\n",
        "nstl = process_NSTL(folder_id_manual, config.get(\"nstl\"))\n",
        "oven = process_Oven(config.get(\"spreadsheet_id_oven\"), config.get(\"gid_oven\"), folder_id_auto, file_name_oven)\n",
        "spc = process_SPC(config.get(\"url_spc\"), file_name_spc, folder_id_auto)\n",
        "szr = process_SZR_link(folder_id_auto,  config.get(\"url_szr\"))\n",
        "trp = process_TRP(config.get(\"url_trp\"), file_name_trp, folder_id_auto)\n",
        "vb = pd.concat([process_VB(folder_id_manual, config.get(\"vb1\")), process_VB(folder_id_manual, config.get(\"vb2\"))], ignore_index=True)\n",
        "vs = process_VS(config.get(\"url_vs\"), folder_id_auto, file_name_vs)\n",
        "vm = process_VM(folder_id_auto, config.get(\"vm\"))\n",
        "\n",
        "rcf = process_RCF(folder_id_manual, 'RCF.xlsx', url_rcf, folder_id_auto, file_name_rcf)\n",
        "simua = process_SIMUA(config.get(\"spreadsheet_id_simua\"), config.get(\"gid_simua\"), folder_id_auto, 'SIMUA')\n",
        "pimx = process_PIMX(ftp_host, ftp_user, ftp_pass, config.get(\"pimx\"), \"GrinevichfXML.xml\", \"Grinevichf_drive.xml\", folder_id_auto)\n",
        "dataframes = [alfa, apg, bio, det, dg, hill, mg, ntp, nstl, oven, pimx, rcf, simua, spc, szr, trp, vb, vm, vs]\n",
        "\n",
        "vendors = pd.concat(dataframes, ignore_index=True)\n",
        "vendors = vendors[['name', 'vendor_code', 'price', 'availability', 'stock_status']]\n",
        "if vendors is not None and isinstance(vendors, pd.DataFrame):\n",
        "    nan_rows = vendors[vendors.isnull().any(axis=1)]\n",
        "    print(f\"asdfgh {nan_rows}\")\n",
        "else:\n",
        "    print(\"vendors is None or not a DataFrame.\")\n",
        "\n",
        "print(vendors)\n",
        "df_products = yml_data_to_dataframe(url)\n",
        "\n",
        "if df_products is not None:\n",
        "  print(df_products.head())\n",
        "\n",
        "current_datetime = pd.DataFrame({'updated datetime': [datetime.datetime.now(pytz.timezone('Europe/Kyiv')).strftime('%Y-%m-%d %H:%M:%S')]})\n",
        "\n",
        "write_dataframe_to_google_sheet(df_products, '1iTtRF0xzqvWaqMK8xS7MTV3w0QcvT_qQV3xVw76mhZY', '0', \"A1:G\")\n",
        "write_dataframe_to_google_sheet(vendors, '1zXiaqI7MJZ3vhuaW3w0pJ4P72YE1CMwzvEkWHBU2WiY', '0', \"A1:E\")\n",
        "write_dataframe_to_google_sheet_to_cell(current_datetime, '1S9sWW-_hVdbY5RQqT5euo4pQEN_6JOnctlsOh2wbr7Y', '0', \"L2:L\", 12, 1)\n",
        "write_dataframe_to_google_sheet_to_cell(current_datetime, '1zXiaqI7MJZ3vhuaW3w0pJ4P72YE1CMwzvEkWHBU2WiY', '0', \"G2:G\", 7, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evyrqBt3YeLX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f96619ab-387b-4c96-ebea-d8c91a39a463"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page loaded successfully.\n",
            "Login details entered successfully!\n",
            "Login button clicked!\n",
            "Redirected to /uk/catalog page after login.\n",
            "Navigated to /uk/cabinet/dump\n",
            "Final Download URL: https://b2b.dober-man.com.ua/uk/inner/cabinet/download/UAP3AVX9ZBFFQPTH\n",
            "Download link: https://b2b.dober-man.com.ua/uk/inner/cabinet/download/UAP3AVX9ZBFFQPTH\n",
            "File downloaded successfully.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BytesIO at 0x7978f20cbd80>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "\n",
        "def get_download_link(username: str, password: str) -> str:\n",
        "    chrome_options = Options()\n",
        "    chrome_options.add_argument('--headless')\n",
        "    chrome_options.add_argument('--no-sandbox')\n",
        "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "    driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "    try:\n",
        "        # Open the login page\n",
        "        driver.get('https://b2b.dober-man.com.ua/')\n",
        "        print(\"Page loaded successfully.\")\n",
        "\n",
        "        # Find and fill the login form\n",
        "        username_field = WebDriverWait(driver, 10).until(\n",
        "            EC.presence_of_element_located((By.CSS_SELECTOR, \"input[autocomplete='login']\"))\n",
        "        )\n",
        "        password_field = WebDriverWait(driver, 10).until(\n",
        "            EC.presence_of_element_located((By.CSS_SELECTOR, \"input[autocomplete='password']\"))\n",
        "        )\n",
        "\n",
        "        username_field.send_keys(username)\n",
        "        password_field.send_keys(password)\n",
        "        print(\"Login details entered successfully!\")\n",
        "\n",
        "        # Find all buttons and locate \"Увійти\" through a loop\n",
        "        buttons = WebDriverWait(driver, 10).until(\n",
        "            EC.presence_of_all_elements_located((By.TAG_NAME, \"button\"))\n",
        "        )\n",
        "\n",
        "        login_button = None\n",
        "        for button in buttons:\n",
        "            if button.text.strip() == \"Увійти\":\n",
        "                login_button = button\n",
        "                break\n",
        "\n",
        "        if login_button:\n",
        "            login_button.click()\n",
        "            print(\"Login button clicked!\")\n",
        "        else:\n",
        "            raise Exception(\"Login button not found!\")\n",
        "\n",
        "        # Wait for redirection after login\n",
        "        WebDriverWait(driver, 20).until(EC.url_contains(\"/uk/catalog\"))\n",
        "        print(\"Redirected to /uk/catalog page after login.\")\n",
        "\n",
        "        # Navigate to the download page\n",
        "        driver.get(\"https://b2b.dober-man.com.ua/uk/cabinet/dump\")\n",
        "        print(\"Navigated to /uk/cabinet/dump\")\n",
        "\n",
        "        # Wait for the download link to be available\n",
        "        download_link = WebDriverWait(driver, 10).until(\n",
        "            EC.presence_of_element_located((By.XPATH, \"//a[contains(@href, '/uk/inner/cabinet/download')]\"))\n",
        "        )\n",
        "        link = download_link.get_attribute('href')\n",
        "        print(f\"Final Download URL: {link}\")\n",
        "\n",
        "        return link\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "    finally:\n",
        "        driver.quit()\n",
        "\n",
        "download_url = get_download_link(\"meow@amigovet.net\", \"V0TBORWY\")\n",
        "print(\"Download link:\", download_url)\n",
        "\n",
        "download_file_from_url(download_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu1DV7LWI-rN",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a539d0de-1d7c-4af5-e6da-faa7c7da3bfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cloudscraper\n",
            "  Downloading cloudscraper-1.2.71-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: pyparsing>=2.4.7 in /usr/local/lib/python3.11/dist-packages (from cloudscraper) (3.2.3)\n",
            "Requirement already satisfied: requests>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from cloudscraper) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from cloudscraper) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.9.2->cloudscraper) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.9.2->cloudscraper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.9.2->cloudscraper) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.9.2->cloudscraper) (2025.4.26)\n",
            "Downloading cloudscraper-1.2.71-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.7/99.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cloudscraper\n",
            "Successfully installed cloudscraper-1.2.71\n",
            "File downloaded successfully.\n",
            "Deleted old file: uaa-2-2.xml (ID: 1YhAqEJZ4NZwazTkTNtLfluIbShSJ5UPw)\n",
            "File uploaded to Google Drive with ID: 1kzluEz8Jh9q3Sl82rhZBGTAc6gyrVIiz\n",
            "Download 100% complete.\n",
            "                     id                                               name  \\\n",
            "0              SPC83315  Жувальна іграшка для собак Nylabone Strong Che...   \n",
            "1              SPC83314  Жувальна іграшка для собак Nylabone Strong Che...   \n",
            "2            1111203546  Ласощі для котів Half&amp;Half м'ясна паличка ...   \n",
            "3            1111203547  Ласощі для собак Half&amp;Half м'ясні палички,...   \n",
            "4            1111193680  Нашийник PROVET SOFTVET для котів та собак дрі...   \n",
            "...                 ...                                                ...   \n",
            "17676  DET4000498022702         Рулетка New Classic S 8m 12kg (трос) - Red   \n",
            "17677  DET4000498022726       Рулетка New Classic S 8m 12kg (трос) - Black   \n",
            "17678  DET4000498023013    Рулетка NEW CLASSIC L 8m/50kg (стрічка) - Синій   \n",
            "17679  DET4000498023006      Рулетка NEW CLASSIC L 8m/50kg (стрічка) - Red   \n",
            "17680  DET4000498023020    Рулетка NEW CLASSIC L 8m/50kg (стрічка) - Black   \n",
            "\n",
            "        price  sale_price availability  \n",
            "0       603.0         0.0      instock  \n",
            "1       431.0         0.0      instock  \n",
            "2        14.0         0.0      instock  \n",
            "3        66.0         0.0      instock  \n",
            "4         0.0         0.0   outofstock  \n",
            "...       ...         ...          ...  \n",
            "17676   812.0         0.0   outofstock  \n",
            "17677   812.0         0.0   outofstock  \n",
            "17678  1328.0         0.0   outofstock  \n",
            "17679  1328.0         0.0   outofstock  \n",
            "17680  1328.0         0.0   outofstock  \n",
            "\n",
            "[17681 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "!pip install cloudscraper\n",
        "import cloudscraper\n",
        "\n",
        "def process_xml_feed(file_io):\n",
        "    \"\"\"Processes an XML file and extracts specific data into a DataFrame.\"\"\"\n",
        "    try:\n",
        "        # Parse the XML file\n",
        "        tree = ET.parse(file_io)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        # List to store extracted data\n",
        "        products = []\n",
        "\n",
        "        # Iterate through each <product> element\n",
        "        for product in root.findall(\".//product\"):\n",
        "            id = get_element_text(product, 'SKU')\n",
        "            title = get_element_text(product, 'title')\n",
        "            price = get_element_text(product, 'price')\n",
        "            sale_price = get_element_text(product, 'sale_price')\n",
        "            availability = get_element_text(product, 'availability')\n",
        "\n",
        "            cleaned_price = float(price.replace(' грн', '').strip()) if price else 0.0\n",
        "            cleaned_sale_price = float(sale_price.replace(' грн', '').strip()) if sale_price else 0.0\n",
        "\n",
        "            product_data = {\n",
        "                'id': id,\n",
        "                'name': title,\n",
        "                'price': cleaned_price,\n",
        "                'sale_price': cleaned_sale_price,\n",
        "                'availability': availability\n",
        "            }\n",
        "            products.append(product_data)\n",
        "\n",
        "        # Create a DataFrame from the products list\n",
        "        df = pd.DataFrame(products)\n",
        "        df['availability'] = df['availability'].apply(lambda x: 'outofstock' if x == 'out of stock' else 'instock')\n",
        "\n",
        "        print(df)\n",
        "        return df\n",
        "\n",
        "    except ET.ParseError as e:\n",
        "        print(f\"Error parsing XML file: {e}\")\n",
        "        return pd.DataFrame()\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def download_large_file(url):\n",
        "    scraper = cloudscraper.create_scraper()  # Handles Cloudflare challenges automatically\n",
        "\n",
        "    try:\n",
        "        response = scraper.get(url, timeout=60)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        file_data = BytesIO(response.content)\n",
        "        file_data.seek(0)\n",
        "\n",
        "        print(\"File downloaded successfully.\")\n",
        "        return file_data\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading file: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def process_feed(url, file_name, folder_id):\n",
        "    \"\"\"Combines the download and processing functions for an XML feed.\"\"\"\n",
        "    # Step 1: Download the XML file\n",
        "    file_io = download_large_file(url)\n",
        "\n",
        "    if file_io:\n",
        "        # Step 2: Parse and process the XML file\n",
        "        file_io.seek(0)\n",
        "        file_id = upload_to_drive_xml(file_io, file_name, folder_id)\n",
        "\n",
        "        if file_id:\n",
        "            uploaded_file_io = read_file_from_drive(file_id)\n",
        "\n",
        "            if uploaded_file_io:\n",
        "              processed_data = process_xml_feed(uploaded_file_io)\n",
        "              return processed_data\n",
        "    else:\n",
        "        print(\"Failed to download the file.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "df_feed = process_feed(feed_url, file_name_feed, folder_id_auto)\n",
        "#write_dataframe_to_google_sheet(df_feed, '1S9sWW-_hVdbY5RQqT5euo4pQEN_6JOnctlsOh2wbr7Y', '0', \"A1:E\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Feze3cmCIil6",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e1aacf3-0f7f-4dc8-ba4e-82abebfb6b50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded successfully.\n",
            "Deleted old file: uaa-2-2.xml (ID: 1kzluEz8Jh9q3Sl82rhZBGTAc6gyrVIiz)\n",
            "File uploaded to Google Drive with ID: 1kiqKcSGxUUseF4iRc_s8eSGpsZaMlUrh\n",
            "Download 100% complete.\n",
            "                     id                                               name  \\\n",
            "0              SPC83315  Жувальна іграшка для собак Nylabone Strong Che...   \n",
            "1              SPC83314  Жувальна іграшка для собак Nylabone Strong Che...   \n",
            "2            1111203546  Ласощі для котів Half&amp;Half м'ясна паличка ...   \n",
            "3            1111203547  Ласощі для собак Half&amp;Half м'ясні палички,...   \n",
            "4            1111193680  Нашийник PROVET SOFTVET для котів та собак дрі...   \n",
            "...                 ...                                                ...   \n",
            "17676  DET4000498022702         Рулетка New Classic S 8m 12kg (трос) - Red   \n",
            "17677  DET4000498022726       Рулетка New Classic S 8m 12kg (трос) - Black   \n",
            "17678  DET4000498023013    Рулетка NEW CLASSIC L 8m/50kg (стрічка) - Синій   \n",
            "17679  DET4000498023006      Рулетка NEW CLASSIC L 8m/50kg (стрічка) - Red   \n",
            "17680  DET4000498023020    Рулетка NEW CLASSIC L 8m/50kg (стрічка) - Black   \n",
            "\n",
            "        price  sale_price availability  \n",
            "0       603.0         0.0      instock  \n",
            "1       431.0         0.0      instock  \n",
            "2        14.0         0.0      instock  \n",
            "3        66.0         0.0      instock  \n",
            "4         0.0         0.0   outofstock  \n",
            "...       ...         ...          ...  \n",
            "17676   812.0         0.0   outofstock  \n",
            "17677   812.0         0.0   outofstock  \n",
            "17678  1328.0         0.0   outofstock  \n",
            "17679  1328.0         0.0   outofstock  \n",
            "17680  1328.0         0.0   outofstock  \n",
            "\n",
            "[17681 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "def process_feed(url, file_name, folder_id):\n",
        "    \"\"\"Combines the download and processing functions for an XML feed.\"\"\"\n",
        "    # Step 1: Download the XML file\n",
        "    file_io = download_large_file(url)\n",
        "\n",
        "    if file_io:\n",
        "        # Step 2: Parse and process the XML file\n",
        "        file_io.seek(0)\n",
        "        file_id = upload_to_drive_xml(file_io, file_name, folder_id)\n",
        "\n",
        "        if file_id:\n",
        "            uploaded_file_io = read_file_from_drive(file_id)\n",
        "\n",
        "            if uploaded_file_io:\n",
        "              processed_data = process_xml_feed(uploaded_file_io)\n",
        "              return processed_data\n",
        "    else:\n",
        "        print(\"Failed to download the file.\")\n",
        "        return pd.DataFrame()\n",
        "df_feed = process_feed(feed_url, file_name_feed, folder_id_auto)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}